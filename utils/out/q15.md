# BEGIN PROB

Let $\vec{x} = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}$. Consider the
function $\displaystyle Q(\vec x) = x_1^2 - 2x_1x_2 + 3x_2^2 - 1$.

# BEGIN SUBPROB

Fill in the blank to complete the definition of $\nabla Q(\vec x)$, the
gradient of $Q$.

$$\nabla Q(\vec x) = \begin{bmatrix} 2(x_1 - x_2) \\ \\ \_\_\_\_ \end{bmatrix}$$

What goes in the blank? Show your work, and put a your final answer,
which should be an **expression involving $x_1$ and/or $x_2$**.

::: responsebox
2in
:::

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

We decide to use gradient descent to minimize $Q$, using an initial
guess of $\vec x^{(0)} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$ and a
learning rate/step size of $\alpha$.

If after one iteration of gradient descent, we have
$\vec{x}^{(1)} = \begin{bmatrix} 1 \\ -4 \end{bmatrix}$, what is
$\alpha$?

( ) $\displaystyle \frac{1}{4}$

( ) $\displaystyle \frac{1}{2}$

( ) $\displaystyle \frac{3}{4}$

( ) $\displaystyle \frac{5}{4}$

( ) $\displaystyle \frac{3}{2}$

( ) $\displaystyle \frac{5}{2}$

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# END PROB