# BEGIN PROB

Suppose we'd like to build a $L_1$-regularized (LASSO) regression model
to predict the width of a fish, given its height and weight. To choose a
value of $\lambda$ (the regularization hyperparameter) from the list
$[0.01, 0.1, 1, 10]$, we perform $k$-fold cross-validation with $k=4$.

# BEGIN SUBPROB

Consider the following optimal parameter vectors, each of which came
from minimizing $L_1$-regularized empirical risk using a different value
of $\lambda$.

(In each parameter vector, the 0th component represents the intercept
term, the 1st component represents the coefficient on height, and the
2nd component represents the coefficient on weight.)

$$\vec{w}_a^* = \begin{bmatrix} 2.6999 \\ 0.0105 \\ 0.0041 \end{bmatrix} \qquad
\vec{w}_b^* = \begin{bmatrix} 3.0674 \\ 0.0000 \\ 0.0034 \end{bmatrix} \qquad
\vec{w}_c^* = \begin{bmatrix} 2.0728 \\ 0.1236 \\ 0.0031 \end{bmatrix}$$

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Suppose, just for this part, that:

-   Our entire dataset has $N$ rows.

-   To split the dataset of $N$ rows into training and test sets, we use
    `train_test_split` with `test_size=0.2`.

While performing 4-fold cross-validation, each time a model is trained,
90 points are used to train the model. What is the value of $N$?

( ) 100

( ) 108

( ) 120

( ) 150

( ) 180

( ) None of these

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Average validation mean squared errors are shown in the table below.

:::: center
::: array
\|c\|c\|c\|c\|c\| & & & &\
= 0.01 & 15 & 9 & 12 & 12\
= 0.1 & 12 & 18 & 6 & 12\
= 1 & 3 & 12 & 15 & m\
= 10 & 18 & 6 & 3 & 9\
:::
::::

Given that $\lambda = 1$ is the hyperparameter with the best
cross-validation performance above, provide the best possible
upper-bound for a value of $m$. That is, find $M$ such that, as long as
$m < M$, $\lambda = 1$ is the best choice of $\lambda$. Give your answer
as a **constant with no variables**.

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# END PROB