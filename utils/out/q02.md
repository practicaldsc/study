# BEGIN PROB

Suppose we'd like to build a regression model to predict the width of a
fish, given its height and weight.

# BEGIN SUBPROB

For each of several model instances, we train a model twice --- once
with the features as-is, and once with standardized features. In other
words:

    # Without standardization
    model = ModelClass() # e.g. model = Lasso(alpha=10000)
    model.fit(X, y)

    # With standardization
    model_std = make_pipeline(StandardScaler(), ModelClass())
    model_std.fit(X, y)

We say a model is **standardization invariant** if its training mean
squared error is **guaranteed** to be the same, with or without
standardization. Which of the models below are standardization
invariant? **Select all** that apply.

[ ] `LinearRegression()`

[ ] `Ridge(alpha=10)`

[ ] `Lasso(alpha=1)`

[ ] `Lasso(alpha=10000)`

[ ] `DecisionTreeRegressor(max_depth=3)`

[ ] `KNeighborsRegressor(n_neighbors=5)`

[ ] `KNeighborsRegressor(n_neighbors=8)`

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Consider the two model instances below.

    once = make_pipeline(StandardScaler(), ModelClass())
    twice = make_pipeline(StandardScaler(), StandardScaler(), ModelClass())

True or False: As long as `ModelClass()` is a valid regression model in
`sklearn` that behaves deterministically\*, `once` and `twice` are
**guaranteed** to have the same training mean squared error.

( ) True

( ) False

*\*By this, we mean that the model makes the same predictions every time
it is fit on the same training set. Technically, not all models behave
this way.*

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# END PROB