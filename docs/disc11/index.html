<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Gradient Descent and Classification</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../assets/theme.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Gradient Descent and Classification</h1>
</header>
<p><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
<!-- add after bootstrap.min.css -->
<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css"/>
<!-- add after bootstrap.min.js or bootstrap.bundle.min.js -->
<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script></p>
<!-- for difficulty gauges-->
<script src="https://cdn.plot.ly/plotly-2.16.1.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-B947E6J6H4"></script> -->
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  // gtag('js', new Date());

  // gtag('config', 'G-B947E6J6H4');
</script>
<p><a href="../index.html">← return to study.practicaldsc.org</a></p>
<hr />
<p>The problems in this worksheet are taken from past exams in similar
classes. Work on them <strong>on paper</strong>, since the exams you
take in this course will also be on paper. <br><br>We encourage you to
complete this worksheet in a live discussion section. Solutions will be
made available after all discussion sections have concluded. You don’t
need to submit your answers anywhere.<br><br><b>Note: We do not plan to
cover all problems here in the live discussion section</b>; the problems
we don’t cover can be used for extra practice.</p>
<hr />
<h2 id="problem-1">Problem 1</h2>
<p>Let <span class="math inline">\vec{x} = \begin{bmatrix} x_1 \\ x_2
\end{bmatrix}</span>. Consider the function <span
class="math inline">g(\vec{x}) = (x_1 - 3)^2 + (x_1^2 -
x_2)^2</span>.</p>
<p><br></p>
<h3 id="problem-1.1">Problem 1.1</h3>
<p>Find <span class="math inline">\nabla g(\vec{x})</span>, the gradient
of <span class="math inline">g(\vec{x})</span>, and use it to show that
<span class="math inline">\nabla g\left( \begin{bmatrix} -1 \\ 1
\end{bmatrix} \right) = \begin{bmatrix} -8 \\ 0
\end{bmatrix}</span>.</p>
<p><br></p>
<h3 id="problem-1.2">Problem 1.2</h3>
<p>We’d like to find the vector <span
class="math inline">\vec{x}^*</span> that minimizes <span
class="math inline">g(\vec{x})</span> using gradient descent. Perform
one iteration of gradient descent by hand, using the initial guess <span
class="math inline">\vec{x}^{(0)} = \begin{bmatrix} -1 \\ 1
\end{bmatrix}</span> and the learning rate <span
class="math inline">\alpha = \frac{1}{2}</span>. In other words, what is
<span class="math inline">\vec{x}^{(1)}</span>?</p>
<p><br></p>
<h3 id="problem-1.3">Problem 1.3</h3>
<p>Consider the function <span class="math inline">f(t) = (t - 3)^2 +
(t^2 - 1)^2</span>. Select the true statement below.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">f(t)</span> is convex and has a global
minimum.</p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">f(t)</span> is not convex, but has a global
minimum.</p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">f(t)</span> is convex, but doesn’t have a
global minimum.</p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">f(t)</span> is not convex and doesn’t have
a global minimum.</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-2">Problem 2</h2>
<p>Suppose we fit five different classifiers that predict whether a
product is designed for sensitive skin, given its price and number of
ingredients. In the five decision boundaries below, the gray-shaded
regions represent areas in which the classifier would predict that the
product <strong>is</strong> designed for sensitive skin (i.e. predict
class 1).</p>
<figure style="display: flex; flex-wrap: wrap; gap: 10px;">
    <div class="minipage">
        <img src="../assets/images/fa24-final/db1.png" width="300"/>
    </div>
    <div class="minipage">
        <img src="../assets/images/fa24-final/db2.png" width="300"/>
    </div>
    <div class="minipage">
        <img src="../assets/images/fa24-final/db3.png" width="300"/>
    </div>
    <div class="minipage">
        <img src="../assets/images/fa24-final/db4.png" width="300"/>
    </div>
    <div class="minipage">
        <img src="../assets/images/fa24-final/db5.png" width="300"/>
    </div>
</figure>
<p><br></p>
<h3 id="problem-2.1">Problem 2.1</h3>
<p>Which model does Decision Boundary 1 correspond to?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">k</span>-nearest neighbors with <span class="math inline">k = 3</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">k</span>-nearest neighbors with <span class="math inline">k = 100</span></p></li>
<li><p><input type="radio" disabled="" /> Decision tree with <span class="math inline">\text{max depth} =
3</span></p></li>
<li><p><input type="radio" disabled="" /> Decision tree with <span class="math inline">\text{max depth} =
15</span></p></li>
<li><p><input type="radio" disabled="" /> Logistic regression</p></li>
</ul>
<p><br></p>
<h3 id="problem-2.2">Problem 2.2</h3>
<p>Which model does Decision Boundary 2 correspond to?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">k</span>-nearest neighbors with <span class="math inline">k = 3</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">k</span>-nearest neighbors with <span class="math inline">k = 100</span></p></li>
<li><p><input type="radio" disabled="" /> Decision tree with <span class="math inline">\text{max depth} =
3</span></p></li>
<li><p><input type="radio" disabled="" /> Decision tree with <span class="math inline">\text{max depth} =
15</span></p></li>
<li><p><input type="radio" disabled="" /> Logistic regression</p></li>
</ul>
<p><br></p>
<h3 id="problem-2.3">Problem 2.3</h3>
<p>Which model does Decision Boundary 3 correspond to?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">k</span>-nearest neighbors with <span class="math inline">k = 3</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">k</span>-nearest neighbors with <span class="math inline">k = 100</span></p></li>
<li><p><input type="radio" disabled="" /> Decision tree with <span class="math inline">\text{max depth} =
3</span></p></li>
<li><p><input type="radio" disabled="" /> Decision tree with <span class="math inline">\text{max depth} =
15</span></p></li>
<li><p><input type="radio" disabled="" /> Logistic regression</p></li>
</ul>
<p><br></p>
<h3 id="problem-2.4">Problem 2.4</h3>
<p>Which model does Decision Boundary 4 correspond to?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">k</span>-nearest neighbors with <span class="math inline">k = 3</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">k</span>-nearest neighbors with <span class="math inline">k = 100</span></p></li>
<li><p><input type="radio" disabled="" /> Decision tree with <span class="math inline">\text{max depth} =
3</span></p></li>
<li><p><input type="radio" disabled="" /> Decision tree with <span class="math inline">\text{max depth} =
15</span></p></li>
<li><p><input type="radio" disabled="" /> Logistic regression</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-3">Problem 3</h2>
<p>After fitting a <code>BillyClassifier</code> on our training set, we
use it to make predictions on an unseen test set. Our results are
summarized in the following confusion matrix.</p>
<center><img src='../assets/images/old-from-80/sp22-final/confusion-2.png' width=50%></center>
<p><br></p>
<h3 id="problem-3.1">Problem 3.1</h3>
<p>What is the recall of our classifier? Give your answer as a fraction
(it does not need to be simplified).</p>
<p><br></p>
<h3 id="problem-3.2">Problem 3.2</h3>
<p>The accuracy of our classifier is <span
class="math inline">\frac{69}{117}</span>. How many <strong>true
negatives</strong> did our classifier have? Give your answer as an
integer.</p>
<p><br></p>
<h3 id="problem-3.3">Problem 3.3</h3>
<p>True or False: In order for a binary classifier’s precision and
recall to be equal, the number of mistakes it makes must be an even
number.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> True</p></li>
<li><p><input type="radio" disabled="" /> False</p></li>
</ul>
<p><br></p>
<h3 id="problem-3.4">Problem 3.4</h3>
<p>Suppose we are building a classifier that listens to an audio source
(say, from your phone’s microphone) and predicts whether or not it is
Soulja Boy’s 2008 classic “Kiss Me thru the Phone”. Our classifier is
pretty good at detecting when the input stream is “Kiss Me thru the
Phone”, but it often incorrectly predicts that similar sounding songs
are also “Kiss Me thru the Phone”.</p>
<p>Complete the sentence: Our classifier has…</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> low precision and low recall.</p></li>
<li><p><input type="radio" disabled="" /> low precision and high recall.</p></li>
<li><p><input type="radio" disabled="" /> high precision and low recall.</p></li>
<li><p><input type="radio" disabled="" /> high precision and high recall.</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-4">Problem 4</h2>
<p>We decide to build a classifier that takes in a state’s demographic
information and predicts whether, in a given year:</p>
<ul>
<li><p>The state’s mean math score was greater than its mean verbal
score (1), or</p></li>
<li><p>the state’s mean math score was less than or equal to its mean
verbal score (0).</p></li>
</ul>
<p><br></p>
<h3 id="problem-4.1">Problem 4.1</h3>
<p>The simplest possible classifier we could build is one that predicts
the same label (1 or 0) every time, independent of all other
features.</p>
<p>Consider the following statement:</p>
<p><em>If <code>a &gt; b</code>, then the constant classifier that
maximizes training accuracy predicts 1 every time; otherwise, it
predicts 0 every time.</em></p>
<p>For which combination of <code>a</code> and <code>b</code> is the
above statement <strong>not guaranteed</strong> to be true?</p>
<p><em>Note: Treat <code>sat</code> as our training set.</em></p>
<p>Option 1:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> (sat[<span class="st">&#39;Math&#39;</span>] <span class="op">&gt;</span> sat[<span class="st">&#39;Verbal&#39;</span>]).mean()</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
<p>Option 2:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> (sat[<span class="st">&#39;Math&#39;</span>] <span class="op">-</span> sat[<span class="st">&#39;Verbal&#39;</span>]).mean()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
<p>Option 3:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> (sat[<span class="st">&#39;Math&#39;</span>] <span class="op">-</span> sat[<span class="st">&#39;Verbal&#39;</span>] <span class="op">&gt;</span> <span class="dv">0</span>).mean()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
<p>Option 4:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> ((sat[<span class="st">&#39;Math&#39;</span>] <span class="op">/</span> sat[<span class="st">&#39;Verbal&#39;</span>]) <span class="op">&gt;</span> <span class="dv">1</span>).mean() <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Option 1</p></li>
<li><p><input type="radio" disabled="" /> Option 2</p></li>
<li><p><input type="radio" disabled="" /> Option 3</p></li>
<li><p><input type="radio" disabled="" /> Option 4</p></li>
</ul>
<p><br></p>
<h3 id="problem-4.2">Problem 4.2</h3>
<p>Suppose we train a classifier, named Classifier 1, and it achieves an
accuracy of <span class="math inline">\frac{5}{9}</span> on our training
set.</p>
<p>Typically, root mean squared error (RMSE) is used as a performance
metric for regression models, but mathematically, nothing is stopping us
from using it as a performance metric for classification models as
well.</p>
<p>What is the RMSE of Classifier 1 on our training set? Give your
answer as a <strong>simplified fraction</strong>.</p>
<p><br></p>
<h3 id="problem-4.3">Problem 4.3</h3>
<p>While Classifier 1’s accuracy on our training set is <span
class="math inline">\frac{5}{9}</span>, its accuracy on our test set is
<span class="math inline">\frac{1}{4}</span>. Which of the following
scenarios is most likely?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Classifier 1 overfit to our training set; we need to increase its
complexity.</p></li>
<li><p><input type="radio" disabled="" /> Classifier 1 overfit to our training set; we need to decrease its
complexity.</p></li>
<li><p><input type="radio" disabled="" /> Classifier 1 underfit to our training set; we need to increase its
complexity.</p></li>
<li><p><input type="radio" disabled="" /> Classifier 1 underfit to our training set; we need to decrease its
complexity.</p></li>
</ul>
<p><br></p>
<p>For the remainder of this question, suppose we train another
classifier, named Classifier 2, again on our training set. Its
performance on the training set is described in the confusion matrix
below. Note that the columns of the confusion matrix have been
separately normalized so that each has a sum of 1.</p>
<center><img src='../assets/images/old-from-80/wi23-final/conf-matrix.png' width=30%></center>
<p><br></p>
<h3 id="problem-4.4">Problem 4.4</h3>
<p>Suppose <code>conf</code> is the DataFrame above. Which of the
following evaluates to a Series of length 2 whose only unique value is
the number <code>1</code>?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <code>conf.sum(axis=0)</code></p></li>
<li><p><input type="radio" disabled="" /> <code>conf.sum(axis=1)</code></p></li>
</ul>
<p><br></p>
<h3 id="problem-4.5">Problem 4.5</h3>
<p>Fill in the blank: the ___ of Classifier 2 is guaranteed to be
0.6.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> precision</p></li>
<li><p><input type="radio" disabled="" /> recall</p></li>
</ul>
<p><br></p>
<p>For your convenience, we show the column-normalized confusion matrix
from the previous page below. You will need to use the specific numbers
in this matrix when answering the following subpart.</p>
<center><img src='../assets/images/old-from-80/wi23-final/conf-matrix.png' width=30%></center>
<p><br></p>
<h3 id="problem-4.6">Problem 4.6</h3>
<p>Suppose a fraction <span class="math inline">\alpha</span> of the
labels in the training set are actually 1 and the remaining <span
class="math inline">1 - \alpha</span> are actually 0. The accuracy of
Classifier 2 is 0.65. What is the value of <span
class="math inline">\alpha</span>? </p>
<p>Hint: If you’re unsure on how to proceed, here are some guiding
questions:</p>
<ul>
<li><p>Suppose the number of <span class="math inline">y</span>-values
that are actually 1 is <span class="math inline">A</span> and that the
number of <span class="math inline">y</span>-values that are actually 0
is <span class="math inline">B</span>. In terms of <span
class="math inline">A</span> and <span class="math inline">B</span>,
what is the accuracy of Classifier 2? Remember, you’ll need to refer to
the numbers in the confusion matrix above.</p></li>
<li><p>What is the relationship between <span
class="math inline">A</span>, <span class="math inline">B</span>, and
<span class="math inline">\alpha</span>? How does it simplify your
calculation for the accuracy in the previous step?</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-5">Problem 5</h2>
<p>Consider the dataset of four values, <span class="math inline">y_1 =
-2, y_2 = -1, y_3 = 2, y_4 = 4</span>. Suppose we’d like to use gradient
descent to find the constant prediction, <span
class="math inline">h^*</span>, that minimizes mean squared error on
this dataset.</p>
<p><br></p>
<h3 id="problem-5.1">Problem 5.1</h3>
<p>Write down the expression of mean square error and its derivative
given this dataset.</p>
<p><br></p>
<h3 id="problem-5.2">Problem 5.2</h3>
<p>Suppose you choose an initial guess of <span
class="math inline">h^{(0)}</span> and a learning rate of <span
class="math inline">\alpha = \frac{1}{4}</span>. After two gradient
descent steps, <span class="math inline">h^{(2)} = \frac{1}{4}</span>.
What is the value of <span class="math inline">h^{(0)}</span>?</p>
<p><br></p>
<hr />
<h2 id="problem-6">Problem 6</h2>
<p>Suppose we’d like to use gradient descent to minimize the function
<span class="math inline">f(x) = x^3 + x^2</span>. Suppose we choose a
learning rate of <span class="math inline">\alpha =
\frac{1}{4}</span>.</p>
<p><br></p>
<h3 id="problem-6.1">Problem 6.1</h3>
<p>Suppose <span class="math inline">x^{(t)}</span> is our guess of the
minimizing input <span class="math inline">x^{*}</span> at timestep
<span class="math inline">t</span>, i.e. <span
class="math inline">x^{(t)}</span> is the result of performing <span
class="math inline">t</span> iterations of gradient descent, given some
initial guess. Write an expression for <span
class="math inline">x^{(t+1)}</span>. Your answer should be an
expression involving <span class="math inline">x^{(t)}</span> and some
constants.</p>
<p><br></p>
<h3 id="problem-6.2">Problem 6.2</h3>
<p>Suppose <span class="math inline">x^{(0)} = -1</span>. - What is the
value of <span class="math inline">x^{(1)}</span>? - Will gradient
descent eventually converge, given the initial guess <span
class="math inline">x^{(0)} = -1</span> and step size <span
class="math inline">\alpha = \frac{1}{4}</span>?</p>
<p><br></p>
<h3 id="problem-6.3">Problem 6.3</h3>
<p>Suppose <span class="math inline">x^{(0)} = 1</span>. - What is the
value of <span class="math inline">x^{(1)}</span>? - Will gradient
descent eventually converge, given the initial guess <span
class="math inline">x^{(0)} = 1</span> and step size <span
class="math inline">\alpha = \frac{1}{4}</span>?</p>
<p><br></p>
<hr />
<h2 id="problem-7">Problem 7</h2>
<p>Suppose we want to minimize the function</p>
<p><span class="math display">R(h) = e^{(h + 1)^2}</span></p>
<p><br></p>
<h3 id="problem-7.1">Problem 7.1</h3>
<p>Without using gradient descent or calculus, what is the value <span
class="math inline">h^*</span> that minimizes <span
class="math inline">R(h)</span>?</p>
<p><br></p>
<h3 id="problem-7.2">Problem 7.2</h3>
<p>Now, suppose we want to use gradient descent to minimize <span
class="math inline">R(h)</span>. Assume we use an initial guess of <span
class="math inline">h^{(1)} = 0</span>. What is <span
class="math inline">h^{(1)}</span>? Give your answer in terms of a
generic step size, <span class="math inline">\alpha</span>, and other
constants. (<span class="math inline">e</span> is a constant.)</p>
<p><br></p>
<h3 id="problem-7.3">Problem 7.3</h3>
<p>Using your answers from the previous two parts, what should we set
the value of <span class="math inline">\alpha</span> to be if we want to
ensure that gradient descent finds <span class="math inline">h^*</span>
after just one iteration?</p>
<p><br></p>
<h3 id="problem-7.4">Problem 7.4</h3>
<p>Below is a graph of <span class="math inline">R(h)</span> with no
axis labels.</p>
<!-- TODO -->
<center><img src="../assets/images/disc11/graph.png" width="500" height="350"></center>
<p>True or False: Given an appropriate choice of step size, <span
class="math inline">\alpha</span>, gradient descent is guaranteed to
find the minimizer of <span class="math inline">R(h)</span>.</p>
<p><br></p>
<hr />
<h2 id="problem-8">Problem 8</h2>
<p>Consider the function <span class="math inline">R(h) = \sqrt{(h -
3)^2 + 1} = ((h - 3)^2 + 1)^{\frac{1}{2}}</span>, which is a convex and
differentiable function with only one local minimum.</p>
<p><br></p>
<h3 id="problem-8.1">Problem 8.1</h3>
<p>Perform by hand two iterations of the gradient descent algorithm on
this function, using an initial prediction of <span
class="math inline">h^{(0)} = 2</span> and a learning rate of <span
class="math inline">\alpha = 2\sqrt{2}</span>. Show your work and your
final answers, <span class="math inline">h^{(1)}</span> and <span
class="math inline">h^{(2)}</span>.</p>
<p><br></p>
<h3 id="problem-8.2">Problem 8.2</h3>
<p>With more iterations, will we eventually converge to the minimizer?
Explain.</p>
<p><br></p>
<hr />
<h2 id="problem-9">Problem 9</h2>
<p>For a given classifier, suppose the first 10 predictions of our
classifier and 10 true observations are as follows: <span
class="math display">
\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\textbf{Predictions} &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0
&amp; 1 &amp; 1 &amp; 1 &amp; 1 \\ \hline
\textbf{True Label} &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0
&amp; 0 &amp; 1 &amp; 1 &amp; 1 \\ \hline
\end{array}
</span></p>
<ol type="1">
<li><p>What is the accuracy of our classifier on these 10
predictions?</p></li>
<li><p>What is the precision on these 10 predictions?</p></li>
<li><p>What is the recall on these 10 predictions?</p></li>
</ol>
<hr />
<h2 id="problem-10">Problem 10</h2>
<p>Consider three classifiers with the following confusion matrices:
<center><img src='../assets/images/old-from-80/fa23-final/dsc80_final_models.png' width=65%></center></p>
<p><br></p>
<h3 id="problem-10.1">Problem 10.1</h3>
<p>Which model has the highest accuracy?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Model A</p></li>
<li><p><input type="radio" disabled="" /> Model B</p></li>
<li><p><input type="radio" disabled="" /> Model C</p></li>
</ul>
<p><br></p>
<h3 id="problem-10.2">Problem 10.2</h3>
<p>Which model has the highest precision?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Model A</p></li>
<li><p><input type="radio" disabled="" /> Model B</p></li>
<li><p><input type="radio" disabled="" /> Model C</p></li>
</ul>
<p><br></p>
<h3 id="problem-10.3">Problem 10.3</h3>
<p>Which model has the highest recall?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Model A</p></li>
<li><p><input type="radio" disabled="" /> Model B</p></li>
<li><p><input type="radio" disabled="" /> Model C</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-11">Problem 11</h2>
<p>Suppose Yutong builds a classifier that predicts whether or not a
hotel provides free parking. The confusion matrix for her classifier,
when evaluated on our training set, is given below.</p>
<center><img src="../assets/images/old-from-80/wi24-final/confusion.png" width=350></center>
<p><br></p>
<h3 id="problem-11.1">Problem 11.1</h3>
<p>What is the precision of Yutong’s classifier? Give your answer as a
simplified fraction.</p>
<p><br></p>
<h3 id="problem-11.2">Problem 11.2</h3>
<p>Fill in the blanks: In order for Yutong’s classifier’s recall to be
equal to its precision, <code>__(i)__</code> must be equal to
<code>__(ii)__</code>.</p>
<ol type="1">
<li>What goes in blank (i)?</li>
</ol>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">A</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">B</span></p></li>
</ul>
<ol start="2" type="1">
<li>What goes in blank (ii)?</li>
</ol>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> 2</p></li>
<li><p><input type="radio" disabled="" /> 3</p></li>
<li><p><input type="radio" disabled="" /> 4</p></li>
<li><p><input type="radio" disabled="" /> 5</p></li>
<li><p><input type="radio" disabled="" /> 6</p></li>
<li><p><input type="radio" disabled="" /> 8</p></li>
<li><p><input type="radio" disabled="" /> 13</p></li>
<li><p><input type="radio" disabled="" /> 14</p></li>
<li><p><input type="radio" disabled="" /> 20</p></li>
<li><p><input type="radio" disabled="" /> 40</p></li>
<li><p><input type="radio" disabled="" /> 50</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
</ul>
<p><br></p>
<h3 id="problem-11.3">Problem 11.3</h3>
<p>Now, suppose both <span class="math inline">A</span> and <span
class="math inline">B</span> are unknown. Fill in the blanks: In order
for Yutong’s classifier’s recall to be equal to its accuracy,
<code>__(i)__</code> must be equal to <code>__(ii)__</code>.</p>
<ol type="1">
<li>What goes in blank (i)?</li>
</ol>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">A + B</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">A - B</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">B - A</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">A \cdot B</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">\frac{A}{B}</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">\frac{B}{A}</span></p></li>
</ul>
<ol start="2" type="1">
<li>What goes in blank (ii)?</li>
</ol>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> 2</p></li>
<li><p><input type="radio" disabled="" /> 3</p></li>
<li><p><input type="radio" disabled="" /> 4</p></li>
<li><p><input type="radio" disabled="" /> 5</p></li>
<li><p><input type="radio" disabled="" /> 6</p></li>
<li><p><input type="radio" disabled="" /> 8</p></li>
<li><p><input type="radio" disabled="" /> 13</p></li>
<li><p><input type="radio" disabled="" /> 14</p></li>
<li><p><input type="radio" disabled="" /> 20</p></li>
<li><p><input type="radio" disabled="" /> 40</p></li>
<li><p><input type="radio" disabled="" /> 50</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
</ul>
<p><em>Hint: To verify your answer, pick an arbitrary value of A, like A
= 10, and solve for the B that sets the model’s recall equal to its
accuracy. Do the specific A and B you find satisfy your answer
above?</em></p>
<p><br></p>
<hr />
<h2 id="section"><span class="math display"> </span></h2>
<h4
id="feedback-find-an-error-still-confused-have-a-suggestion-let-us-know-here.">👋
Feedback: Find an error? Still confused? Have a suggestion? Let us know
<a href="https://forms.gle/xK4DpWXh9rq8AKP37">here</a>.</h4>
<hr />
</body>
</html>
