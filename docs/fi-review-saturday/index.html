<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Final Review, Day 2 (Saturday)</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../assets/theme.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Final Review, Day 2 (Saturday)</h1>
</header>
<p><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
<!-- add after bootstrap.min.css -->
<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css"/>
<!-- add after bootstrap.min.js or bootstrap.bundle.min.js -->
<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script></p>
<!-- for difficulty gauges-->
<script src="https://cdn.plot.ly/plotly-2.16.1.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-B947E6J6H4"></script> -->
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  // gtag('js', new Date());

  // gtag('config', 'G-B947E6J6H4');
</script>
<p><a href="../index.html">← return to study.practicaldsc.org</a></p>
<hr />
<p>The problems in this worksheet are taken from past exams in similar
classes. Work on them <strong>on paper</strong>, since the exams you
take in this course will also be on paper. <br><br>We encourage you to
attempt these problems <strong>before</strong> Saturday’s exam review
session, so that we have enough time to walk through the solutions to
all of the problems. <br><br>We will enable the solutions here after the
review session, though you can find the written solutions to these
problems in other discussion worksheets. <br><br>While you can treat
this as a mock exam of sorts, there are many topics that are in scope
for the final exam that do not appear here, and this may not be
representative of the length of the real Final Exam.</p>
<hr />
<h2 id="problem-1">Problem 1</h2>
<p>Consider the dataset shown below.</p>
<div class="center">
<table>
<thead>
<tr>
<th style="text-align: left;"><span
class="math inline">x^{(1)}</span></th>
<th style="text-align: left;"><span
class="math inline">x^{(2)}</span></th>
<th style="text-align: left;"><span
class="math inline">x^{(3)}</span></th>
<th style="text-align: left;"><span class="math inline">y</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">0</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">-5</td>
</tr>
<tr>
<td style="text-align: left;">3</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">7</td>
</tr>
<tr>
<td style="text-align: left;">5</td>
<td style="text-align: left;">-1</td>
<td style="text-align: left;">-3</td>
<td style="text-align: left;">4</td>
</tr>
<tr>
<td style="text-align: left;">0</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">2</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<h3 id="problem-1.1">Problem 1.1</h3>
<p>We want to use multiple regression to fit a prediction rule of the
form <span class="math display">H(x_i^{(1)}, x_i^{(2)}, x_i^{(3)}) = w_0
+ w_1 x_i^{(1)} x_i^{(3)} + w_2 (x_i^{(2)} - x_i^{(3)})^2.</span> Write
down the design matrix <span class="math inline">X</span> and
observation vector <span class="math inline">\vec{y}</span> for this
scenario. No justification needed.</p>
<p><br></p>
<h3 id="problem-1.2">Problem 1.2</h3>
<p>For the <span class="math inline">X</span> and <span
class="math inline">\vec{y}</span> that you have written down, let <span
class="math inline">\vec{w}</span> be the optimal parameter vector,
which comes from solving the normal equations <span
class="math inline">X^TX\vec{w}=X^T\vec{y}</span>. Let <span
class="math inline">\vec{e} = \vec{y} - X \vec{w}</span> be the error
vector, and let <span class="math inline">e_i</span> be the <span
class="math inline">i</span>th component of this error vector. Show that
<span class="math display">4e_1+e_2+4e_3+e_4=0.</span></p>
<p><br></p>
<hr />
<h2 id="problem-2">Problem 2</h2>
<p>The two plots below show the total number of boots (top) and sandals
(bottom) purchased per month in the <code>df</code> table. Assume that
there is one data point per month.</p>
<center><img src="../../assets/images/disc09/boot.png" style="width: 100%; height: auto;"></center>
<center><img src="../../assets/images/disc09/sandal.png" style="width: 100%; height: auto;"></center>
<p>For each of the following regression models, use the visualizations
shown above to select the value that is <strong>closest</strong> to the
fitted model weights. If it is not possible to determine the model
weight, select “Not enough info”. For the models below:</p>
<ul>
<li>The notation <span class="math inline">\text{boot}</span> refers to
the number of boots sold.</li>
<li>The notation <span class="math inline">\text{sandal}</span> refers
to the number of sandals sold.</li>
<li><span class="math inline">\text{summer}=1</span> is a column with
value 1 if the month is between March (03) and August (08),
inclusive.</li>
<li><span class="math inline">\text{winter}=1</span> is a column with
value 1 if the month is between September (09) and February (02),
inclusive.</li>
</ul>
<p><br></p>
<h3 id="problem-2.1">Problem 2.1</h3>
<p><span class="math inline">\text{predicted boot}_i = w_0</span></p>
<p><span class="math inline">w_0</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 50</p></li>
<li><p><input type="radio" disabled="" /> 100</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<p><br></p>
<h3 id="problem-2.2">Problem 2.2</h3>
<p><span class="math inline">\text{predicted boot}_i = w_0 + w_1 \cdot
\text{sandals}_i</span></p>
<p><span class="math inline">w_0</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -100</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 100</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><span class="math inline">w_1</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -100</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 100</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<p><br></p>
<h3 id="problem-2.3">Problem 2.3</h3>
<p><span class="math inline">\text{predicted boot}_i  = w_0 + w_1 \cdot
(\text{summer=1})_i</span></p>
<p><span class="math inline">w_0</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -100</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 100</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><span class="math inline">w_1</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -80</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<p><br></p>
<h3 id="problem-2.4">Problem 2.4</h3>
<p><span class="math inline">\text{predicted sandal}_i  = w_0 + w_1
\cdot (\text{summer=1})_i</span></p>
<p><span class="math inline">w_0</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -20</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 20</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><span class="math inline">w_1</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -80</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<p><br></p>
<h3 id="problem-2.5">Problem 2.5</h3>
<p><span class="math inline">\text{predicted sandal}_i  = w_0 + w_1
\cdot (\text{summer=1})_i + w_2 \cdot (\text{winter=1})_i</span></p>
<p><span class="math inline">w_0</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -20</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 20</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><span class="math inline">w_1</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -80</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><span class="math inline">w_2</span>:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -80</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-3">Problem 3</h2>
<p>We will aim to build a classifier that takes in demographic
information about a state from a particular year and predicts whether or
not the state’s mean math score is higher than its mean verbal score
that year.</p>
<p>In honor of the
<a href="https://www.reddit.com/r/UCSD/comments/11o0w9r/chicken_event/">rotisserie
chicken event</a> on UCSD’s campus in March of 2023,
<code>sklearn</code> released a new classifier class called
<code>ChickenClassifier</code>.</p>
<p><br></p>
<h3 id="problem-3.1">Problem 3.1</h3>
<p><code>ChickenClassifier</code>s have many hyperparameters, one of
which is <code>height</code>. As we increase the value of
<code>height</code>, the model variance of the resulting
<code>ChickenClassifier</code> also increases.</p>
<p>First, we consider the training and testing accuracy of a
<code>ChickenClassifier</code> trained using various values of
<code>height</code>. Consider the plot below.</p>
<center><img src='../assets/images/disc10/accuracy.png' width=30%></center>
<ul>
<li>Note that <strong>accuracy</strong> is a metric that measures how
well a classifier performs by comparing the number of correct
predictions to the total number of predictions.</li>
</ul>
<p>Which of the following depicts <strong>training accuracy
vs. <code>height</code></strong>?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Option 1</p></li>
<li><p><input type="radio" disabled="" /> Option 2</p></li>
<li><p><input type="radio" disabled="" /> Option 3</p></li>
</ul>
<p>Which of the following depicts <strong>testing accuracy
vs. <code>height</code></strong>?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Option 1</p></li>
<li><p><input type="radio" disabled="" /> Option 2</p></li>
<li><p><input type="radio" disabled="" /> Option 3</p></li>
</ul>
<p><br></p>
<p><code>ChickenClassifier</code>s have another hyperparameter,
<code>color</code>, for which there are four possible values:
<code>"yellow"</code>, <code>"brown"</code>, <code>"red"</code>, and
<code>"orange"</code>. To find the optimal value of <code>color</code>,
we perform <span class="math inline">k</span>-fold cross-validation with
<span class="math inline">k=4</span>. The results are given in the table
below.</p>
<center><img src='../assets/images/disc10/CV.png' width=30%></center>
<p><br></p>
<h3 id="problem-3.2">Problem 3.2</h3>
<p>Which value of <code>color</code> has the best average validation
accuracy?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <code>"yellow"</code></p></li>
<li><p><input type="radio" disabled="" /> <code>"brown"</code></p></li>
<li><p><input type="radio" disabled="" /> <code>"red"</code></p></li>
<li><p><input type="radio" disabled="" /> <code>"orange"</code></p></li>
</ul>
<p><br></p>
<h3 id="problem-3.3">Problem 3.3</h3>
<p>True or False: It is possible for a hyperparameter value to have the
best average validation accuracy across all folds, but not have the best
validation accuracy in any one particular fold.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> True</p></li>
<li><p><input type="radio" disabled="" /> False</p></li>
</ul>
<p><br></p>
<h3 id="problem-3.4">Problem 3.4</h3>
<p>Now, instead of finding the best <code>height</code> and best
<code>color</code> individually, we decide to perform a grid search that
uses <span class="math inline">k</span>-fold cross-validation to find
the combination of <code>height</code> and <code>color</code> with the
best average validation accuracy.</p>
<p>For the purposes of this question, assume that:</p>
<ul>
<li>We are performing <span class="math inline">k</span>-fold cross
validation.</li>
<li>Our training set contains <span class="math inline">n</span> rows,
where <span class="math inline">n</span> is greater than 5 and is a
multiple of <span class="math inline">k</span>.</li>
<li>There are <span class="math inline">h_1</span> possible values of
<code>height</code> and <span class="math inline">h_2</span> possible
values of <code>color</code>.</li>
</ul>
<p>Consider the following three subparts:</p>
<ul>
<li>A. What is the size of each fold?</li>
<li>B. How many times is row 5 in the training set used for
training?</li>
<li>C. How many times is row 5 in the training set used for
validation?</li>
</ul>
<p>Choose from the following options.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">\frac{k}{n}</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">\frac{n}{k}</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">\frac{n}{k} \cdot (k - 1)</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">h_1h_2k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">h_1h_2(k-1)</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">\frac{nh_1h_2}{k}</span></p></li>
<li><p><input type="radio" disabled="" /> None of the above</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-4">Problem 4</h2>
<p>Consider the least squares regression model, <span
class="math inline">\vec{h} = X \vec{w}</span>. Assume that <span
class="math inline">X</span> and <span
class="math inline">\vec{h}</span> refer to the design matrix and
hypothesis vector for our training data, and <span
class="math inline">\vec y</span> is the true observation vector.</p>
<p>Let <span class="math inline">\vec{w}_\text{OLS}^*</span> be the
parameter vector that minimizes mean squared error without
regularization. Specifically:</p>
<p><span class="math inline">\vec{w}_\text{OLS}^*</span> = <span
class="math inline">\arg\underset{\vec{w}}{\min} \frac{1}{n} \| \vec{y}
- X \vec{w} \|^2_2</span></p>
<p>Let <span class="math inline">\vec{w}_\text{ridge}^*</span> be the
parameter vector that minimizes mean squared error with <span
class="math inline">L_2</span> regularization, using a non-negative
regularization hyperparameter <span class="math inline">\lambda</span>
(i.e. ridge regression). Specifically:</p>
<p><span class="math inline">\vec{w}_\text{ridge}^*</span> = <span
class="math inline">\arg\underset{\vec{w}}{\min} \frac{1}{n} \| \vec y -
X \vec{w} \|^2_2 + \lambda \sum_{j=1}^{p} w_j^2</span></p>
<p>For each of the following problems, fill in the blank.</p>
<p><br></p>
<h3 id="problem-4.1">Problem 4.1</h3>
<p>If we set <span class="math inline">\lambda</span> = 0, then <span
class="math inline">\Vert \vec{w}_\text{OLS}^* \Vert^2_2</span> is
<strong>____</strong> <span class="math inline">\Vert
\vec{w}_\text{ridge}^* \Vert^2_2</span></p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> less than</p></li>
<li><p><input type="radio" disabled="" /> equal to</p></li>
<li><p><input type="radio" disabled="" /> greater than</p></li>
<li><p><input type="radio" disabled="" /> impossible to tell</p></li>
</ul>
<p><br></p>
<h3 id="problem-4.2">Problem 4.2</h3>
<p>For each of the remaining parts, you can assume that <span
class="math inline">\lambda</span> is set such that the predicted
response vectors for our two models (<span class="math inline">\vec{h} =
X \vec{w}_\text{OLS}^*</span> and <span class="math inline">\vec{h} = X
\vec{w}_\text{ridge}^*</span>) is different.</p>
<p>The <strong>training</strong> MSE of the model <span
class="math inline">\vec{h} = X \vec{w}_\text{OLS}^*</span> is
<strong>____</strong> than the model <span class="math inline">\vec{h} =
X \vec{w}_\text{ridge}^*</span>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> less than</p></li>
<li><p><input type="radio" disabled="" /> equal to</p></li>
<li><p><input type="radio" disabled="" /> greater than</p></li>
<li><p><input type="radio" disabled="" /> impossible to tell</p></li>
</ul>
<p><br></p>
<h3 id="problem-4.3">Problem 4.3</h3>
<p>Now, assume we’ve fit both models using our training data, and
evaluate both models on some unseen testing data.</p>
<p>The <strong>test</strong> MSE of the model <span
class="math inline">\vec{h} = X \vec{w}_\text{OLS}^*</span> is
<strong>____</strong> than the model <span class="math inline">\vec{h} =
X \vec{w}_\text{ridge}^*</span>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> less than</p></li>
<li><p><input type="radio" disabled="" /> equal to</p></li>
<li><p><input type="radio" disabled="" /> greater than</p></li>
<li><p><input type="radio" disabled="" /> impossible to tell</p></li>
</ul>
<p><br></p>
<h3 id="problem-4.4">Problem 4.4</h3>
<p>Assume that our design matrix <span class="math inline">X</span>
contains a column of all ones. The sum of the residuals of our model
<span class="math inline">\vec{h} = X \vec{w}_\text{ridge}^*</span>
<strong>____</strong>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> equal to 0</p></li>
<li><p><input type="radio" disabled="" /> not necessarily equal to 0</p></li>
</ul>
<p><br></p>
<h3 id="problem-4.5">Problem 4.5</h3>
<p>As we increase <span class="math inline">\lambda</span>, the bias of
the model <span class="math inline">\vec{h} = X
\vec{w}_\text{ridge}^*</span> tends to <strong>____</strong>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> increase</p></li>
<li><p><input type="radio" disabled="" /> stay the same</p></li>
<li><p><input type="radio" disabled="" /> decrease</p></li>
</ul>
<p><br></p>
<h3 id="problem-4.6">Problem 4.6</h3>
<p>As we increase <span class="math inline">\lambda</span>, the model
variance of the model <span class="math inline">\vec{h} = X
\vec{w}_\text{ridge}^*</span> tends to <strong>____</strong>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> increase</p></li>
<li><p><input type="radio" disabled="" /> stay the same</p></li>
<li><p><input type="radio" disabled="" /> decrease</p></li>
</ul>
<p><br></p>
<h3 id="problem-4.7">Problem 4.7</h3>
<p>As we increase <span class="math inline">\lambda</span>, the
observation variance of the model <span class="math inline">\vec{h} = X
\vec{w}_\text{ridge}^*</span> tends to <strong>____</strong>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> increase</p></li>
<li><p><input type="radio" disabled="" /> stay the same</p></li>
<li><p><input type="radio" disabled="" /> decrease</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-5">Problem 5</h2>
<p>Suppose we’d like to use gradient descent to minimize the function
<span class="math inline">f(x) = x^3 + x^2</span>. Suppose we choose a
learning rate of <span class="math inline">\alpha =
\frac{1}{4}</span>.</p>
<p><br></p>
<h3 id="problem-5.1">Problem 5.1</h3>
<p>Suppose <span class="math inline">x^{(t)}</span> is our guess of the
minimizing input <span class="math inline">x^{*}</span> at timestep
<span class="math inline">t</span>, i.e. <span
class="math inline">x^{(t)}</span> is the result of performing <span
class="math inline">t</span> iterations of gradient descent, given some
initial guess. Write an expression for <span
class="math inline">x^{(t+1)}</span>. Your answer should be an
expression involving <span class="math inline">x^{(t)}</span> and some
constants.</p>
<p><br></p>
<h3 id="problem-5.2">Problem 5.2</h3>
<p>Suppose <span class="math inline">x^{(0)} = -1</span>.</p>
<ul>
<li><p>What is the value of <span
class="math inline">x^{(1)}</span>?</p></li>
<li><p>Will gradient descent eventually converge, given the initial
guess <span class="math inline">x^{(0)} = -1</span> and step size <span
class="math inline">\alpha = \frac{1}{4}</span>?</p></li>
</ul>
<p><br></p>
<h3 id="problem-5.3">Problem 5.3</h3>
<p>Suppose <span class="math inline">x^{(0)} = 1</span>.</p>
<ul>
<li><p>What is the value of <span
class="math inline">x^{(1)}</span>?</p></li>
<li><p>Will gradient descent eventually converge, given the initial
guess <span class="math inline">x^{(0)} = 1</span> and step size <span
class="math inline">\alpha = \frac{1}{4}</span>?</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-6">Problem 6</h2>
<p>For a given classifier, suppose the first 10 predictions of our
classifier and 10 true observations are as follows: <span
class="math display">
\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\textbf{Predictions} &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0
&amp; 1 &amp; 1 &amp; 1 &amp; 1 \\ \hline
\textbf{True Label} &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0
&amp; 0 &amp; 1 &amp; 1 &amp; 1 \\ \hline
\end{array}
</span></p>
<ol type="1">
<li><p>What is the accuracy of our classifier on these 10
predictions?</p></li>
<li><p>What is the precision on these 10 predictions?</p></li>
<li><p>What is the recall on these 10 predictions?</p></li>
</ol>
<hr />
<h2 id="problem-7">Problem 7</h2>
<p>Suppose we want to use logistic regression to classify whether a
person survived the sinking of the Titanic. The first 5 rows of our
dataset are given below.</p>
<p><span class="math display">\begin{array}{|c|c|c|c|}
\hline
&amp; \textbf{Age} &amp; \textbf{Survived} &amp; \textbf{Female} \\
\hline
0 &amp; 22.0 &amp; 0 &amp; 0 \\ \hline
1 &amp; 38.0 &amp; 1 &amp; 1 \\ \hline
2 &amp; 26.0 &amp; 1 &amp; 1 \\ \hline
3 &amp; 35.0 &amp; 1 &amp; 1 \\ \hline
4 &amp; 35.0 &amp; 0 &amp; 0 \\ \hline
\end{array}</span></p>
<p>Suppose after training our logistic regression model we get <span
class="math inline">\vec{w}^* = \begin{bmatrix}
-1.2 \\ -0.005 \\ 2.5
\end{bmatrix}</span>, where <span class="math inline">-1.2</span> is an
intercept term, <span class="math inline">-0.005</span> is the optimal
parameter corresponding to passenger’s age, and <span
class="math inline">2.5</span> is the optimal parameter corresponding to
sex (1 if female, 0 otherwise).</p>
<p><br></p>
<h3 id="problem-7.1">Problem 7.1</h3>
<p>Consider Sı̄lānah Iskandar Nāsı̄f Abı̄ Dāghir Yazbak, a 20 year old
female. What chance did she have to survive the sinking of the Titanic
according to our model? Give your answer as a probability in terms of
<span class="math inline">\sigma</span>. If there is not enough
information, write “not enough information.”</p>
<p><br></p>
<h3 id="problem-7.2">Problem 7.2</h3>
<p>Sı̄lānah Iskandar Nāsı̄f Abı̄ Dāghir Yazbak actually survived. What is
the cross-entropy loss for our prediction in the previous part?</p>
<p><br></p>
<h3 id="problem-7.3">Problem 7.3</h3>
<p>At what age would we predict that a female passenger is more likely
to have survived the Titanic than not? In other words, at what age is
the probability of survival for a female passenger greater than 0.5?</p>
<p><em>Hint: Since <span class="math inline">\sigma(0) = 0.5</span>, we
have that <span class="math inline">\sigma \left( \vec{w}^* \cdot
\text{Aug}(\vec x_i) \right) = 0.5 \implies \vec{w}^* \cdot
\text{Aug}(\vec x_i) = 0</span>.</em></p>
<p><br></p>
<h3 id="problem-7.4">Problem 7.4</h3>
<p>Let <span class="math inline">m</span> be the <strong>odds</strong>
of a given non-female passenger’s survival according to our logistic
regression model, i.e., if the passenger had an 80% chance of survival,
<span class="math inline">m</span> would be 4, since their odds of
survival are <span class="math inline">\frac{0.8}{0.2} = 4</span>.</p>
<p>It turns out we can compute <span class="math inline">f</span>, the
odds of survival for a female passenger of the same age, in terms of
<span class="math inline">m</span>. Give an expression for <span
class="math inline">f</span> in terms of <span
class="math inline">m</span>.</p>
<p><br></p>
<hr />
<h2 id="problem-8">Problem 8</h2>
<p>Consider the following dataset of <span
class="math inline">n=7</span> points in <span
class="math inline">d=2</span> dimensions.</p>
<center><img src="../assets/images/disc13/graph.png" width="500"></center>
<p><br></p>
<h3 id="problem-8.1">Problem 8.1</h3>
<p>Suppose we decide to use agglomerative clustering to cluster the
data. How many possible pairs of clusters could we combine in the first
iteration?</p>
<p><br></p>
<h3 id="problem-8.2">Problem 8.2</h3>
<p>Suppose we want to identify <span class="math inline">k=2</span>
clusters in this dataset using <span class="math inline">k</span>-means
clustering.</p>
<p>Determine the centroids <span class="math inline">\vec{\mu}_1</span>
and <span class="math inline">\vec{\mu}_2</span> that minimize inertia.
(Let <span class="math inline">\vec{\mu}_1</span> be the centroid with a
smaller <span class="math inline">x_1</span> coordinate.) Justify your
answers.</p>
<p><em>Note: You don’t have to run the k-Means Clustering algorithm to
answer this question.</em></p>
<p><br></p>
<h3 id="problem-8.3">Problem 8.3</h3>
<p>What is the total inertia for the centroids you chose in the previous
part? Show your work.</p>
<p><br></p>
<hr />
<h2 id="section"><span class="math display"> </span></h2>
<h4
id="feedback-find-an-error-still-confused-have-a-suggestion-let-us-know-here.">👋
Feedback: Find an error? Still confused? Have a suggestion? Let us know
<a href="https://forms.gle/xK4DpWXh9rq8AKP37">here</a>.</h4>
<hr />
</body>
</html>
