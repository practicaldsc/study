<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Feature Engineering</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../assets/theme.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Feature Engineering</h1>
</header>
<p><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
<!-- add after bootstrap.min.css -->
<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css"/>
<!-- add after bootstrap.min.js or bootstrap.bundle.min.js -->
<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script></p>
<!-- for difficulty gauges-->
<script src="https://cdn.plot.ly/plotly-2.16.1.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-B947E6J6H4"></script> -->
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  // gtag('js', new Date());

  // gtag('config', 'G-B947E6J6H4');
</script>
<p><a href="../index.html">← return to study.practicaldsc.org</a></p>
<hr />
<p>The problems in this worksheet are taken from past exams in similar
classes. Work on them <strong>on paper</strong>, since the exams you
take in this course will also be on paper. <br><br>We encourage you to
complete this worksheet in a live discussion section. Solutions will be
made available after all discussion sections have concluded. You don’t
need to submit your answers anywhere.<br><br><b>Note: We do not plan to
cover all problems here in the live discussion section</b>; the problems
we don’t cover can be used for extra practice.</p>
<hr />
<h2 id="problem-1">Problem 1</h2>
<p>Every week, Lauren goes to her local grocery store and buys a varying
amount of vegetable but always buys exactly one pound of meat (either
beef, fish, or chicken). We use a linear regression model to predict her
total grocery bill. We’ve collected a dataset containing the pounds of
vegetables bought, the type of meat bought, and the total bill. Below we
display the first few rows of the dataset and two plots generated using
the entire training set.</p>
<center><img src='../../assets/images/disc09/dsc80_final_q9.png' width=65%></center>
<p><br></p>
<h3 id="problem-1.1">Problem 1.1</h3>
<p>Suppose we fit the following linear regression models to predict
<code>'total'</code> using the squared loss function. Based on the data
and visualizations shown above, for each of the following models <span
class="math inline">H(x)</span>, determine whether <strong>each fitted
model coefficient <span class="math inline">w^*</span></strong> is
positive (<span class="math inline">+</span>), negative (<span
class="math inline">-</span>), or exactly 0. The notation <span
class="math inline">\text{meat=beef}</span> refers to the one-hot
encoded <code>'meat'</code> column with value <span
class="math inline">1</span> if the original value in the
<code>'meat'</code> column was <code>'beef'</code> and <span
class="math inline">0</span> otherwise. Likewise, <span
class="math inline">\text{meat=chicken}</span> and <span
class="math inline">\text{meat=fish}</span> are the one-hot encoded
<code>'meat'</code> columns for <code>'chicken'</code> and
<code>'fish'</code>, respectively.</p>
<p>For example, in part (iv), you’ll need to provide three answers: one
for <span class="math inline">w_0^*</span> (either positive, negative,
or 0), one for <span class="math inline">w_1^*</span> (either positive,
negative, or 0), and one for <span class="math inline">w_2^*</span>
(either positive, negative, or 0).</p>
<ol type="i">
<li><span class="math inline">H(x) = w_0</span></li>
<li><span class="math inline">H(x) = w_0 + w_1 \cdot
\text{veg}</span></li>
<li><span class="math inline">H(x) = w_0 + w_1 \cdot
\text{(meat=chicken)}</span></li>
<li><span class="math inline">H(x) = w_0 + w_1 \cdot \text{(meat=beef)}
+ w_2 \cdot \text{(meat=chicken)}</span></li>
<li><span class="math inline">H(x) = w_0 + w_1 \cdot \text{(meat=beef)}
+ w_2 \cdot \text{(meat=chicken)} + w_3 \cdot
\text{(meat=fish)}</span></li>
</ol>
<p><br></p>
<h3 id="problem-1.2">Problem 1.2</h3>
<p>Suppose we fit the model <span class="math inline">H(x) = w_0 + w_1
\cdot \text{veg} + w_2 \cdot \text{(meat=beef)} + w_3 \cdot
\text{(meat=fish)}</span>. After fitting, we find that <span
class="math inline">\vec{w^*}=[-3, 5, 8, 12]</span></p>
<p>What is the prediction of this model on the <strong>first</strong>
point in our dataset?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -3</p></li>
<li><p><input type="radio" disabled="" /> 2</p></li>
<li><p><input type="radio" disabled="" /> 5</p></li>
<li><p><input type="radio" disabled="" /> 10</p></li>
<li><p><input type="radio" disabled="" /> 13</p></li>
<li><p><input type="radio" disabled="" /> 22</p></li>
<li><p><input type="radio" disabled="" /> 25</p></li>
</ul>
<p><br></p>
<h3 id="problem-1.3">Problem 1.3</h3>
<p>Following the same model <span class="math inline">H(x)</span> and
weights from the previous problem, what is the loss of this model on the
<strong>second</strong> point in our dataset, using squared error
loss?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 5</p></li>
<li><p><input type="radio" disabled="" /> 6</p></li>
<li><p><input type="radio" disabled="" /> 8</p></li>
<li><p><input type="radio" disabled="" /> 24</p></li>
<li><p><input type="radio" disabled="" /> 25</p></li>
<li><p><input type="radio" disabled="" /> 169</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-2">Problem 2</h2>
<p>Billy’s aunt owns a jewellery store, and gives him data on <span
class="math inline">5000</span> of the diamonds in her store. For each
diamond, we have:</p>
<ul>
<li><strong>carat</strong>: the weight of the diamond, in carats</li>
<li><strong>length</strong>: the length of the diamond, in
centimeters</li>
<li><strong>width</strong>: the width of the diamond, in
centimeters</li>
<li><strong>price</strong>: the value of the diamond, in dollars</li>
</ul>
<p>The first 5 rows of the 5000-row dataset are shown below:</p>
<div>
<table>
<colgroup>
<col style="width: 24%" />
<col style="width: 27%" />
<col style="width: 24%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr>
<th>carat   </th>
<th>length   </th>
<th>width   </th>
<th>price   </th>
</tr>
</thead>
<tbody>
<tr>
<td>0.40</td>
<td>4.81</td>
<td>4.76</td>
<td>1323</td>
</tr>
<tr>
<td>1.04</td>
<td>6.58</td>
<td>6.53</td>
<td>5102</td>
</tr>
<tr>
<td>0.40</td>
<td>4.74</td>
<td>4.76</td>
<td>696</td>
</tr>
<tr>
<td>0.40</td>
<td>4.67</td>
<td>4.65</td>
<td>798</td>
</tr>
<tr>
<td>0.50</td>
<td>4.90</td>
<td>4.95</td>
<td>987</td>
</tr>
</tbody>
</table>
</div>
<p><br> Billy has enlisted our help in predicting the price of a diamond
given various other features.</p>
<p><br></p>
<h3 id="problem-2.1">Problem 2.1</h3>
<p>Suppose we want to fit a linear prediction rule that uses two
features, carat and length, to predict price. Specifically, our
prediction rule will be of the form</p>
<p><span class="math display">\text{predicted price} = w_0 + w_1 \cdot
\text{carat} + w_2 \cdot \text{length}</span></p>
<p><br></p>
<p>We will use least squares to find <span class="math inline">\vec{w}^*
= \begin{bmatrix} w_0^* \\ w_1^* \\ w_2^* \end{bmatrix}</span>.</p>
<p>Write out the first 5 rows of the design matrix, <span
class="math inline">X</span>. Your matrix should not have any variables
in it.</p>
<p><br></p>
<h3 id="problem-2.2">Problem 2.2</h3>
<p>Suppose the optimal parameter vector <span
class="math inline">\vec{w}^*</span> is given by</p>
<p><span class="math display">\vec{w}^* = \begin{bmatrix} 2000 \\ 10000
\\ -1000 \end{bmatrix}</span></p>
<p>What is the predicted price of a diamond with 0.65 carats and a
length of 4 centimeters? Show your work.</p>
<p><br></p>
<h3 id="problem-2.3">Problem 2.3</h3>
<p>Suppose <span class="math inline">\vec{e} = \begin{bmatrix} e_1 \\
e_2 \\ ... \\ e_n \end{bmatrix}</span> is the error/residual vector,
defined as</p>
<p><span class="math display">\vec{e} = \vec{y} - X \vec{w}^*</span></p>
<p>where <span class="math inline">\vec{y}</span> is the observation
vector containing the prices for each diamond.</p>
<p>For each of the following quantities, state whether they are
guaranteed to be equal to 0 the scalar, <span
class="math inline">\vec{0}</span> the vector of all 0s, or neither. No
justification is necessary.</p>
<ul>
<li><span class="math inline">\sum_{i = 1}^n e_i</span></li>
<li><span class="math inline">|| \vec{y} - X \vec{w}^* ||^2</span></li>
<li><span class="math inline">X^TX \vec{w}^*</span></li>
<li><span class="math inline">2X^TX \vec{w}^* - 2X^T\vec{y}</span></li>
</ul>
<p><br></p>
<h3 id="problem-2.4">Problem 2.4</h3>
<p>Suppose we introduce two more features:</p>
<ul>
<li>width alone, and</li>
<li>area, which is defined as length times width</li>
</ul>
<p>Suppose we also decide to remove the intercept term of our prediction
rule. With all of these changes, our prediction rule is now</p>
<p><span class="math display">\text{predicted price} = w_1 \cdot
\text{carat} + w_2 \cdot \text{length} + w_3 \cdot \text{width} + w_4
\cdot (\text{length} \cdot \text{width}) </span></p>
<ul>
<li>Write out just the first 2 rows of the design matrix <span
class="math inline">X</span> for this new prediction rule. You do
<strong>not</strong> need to simplify the numbers in your matrix, it is
fine if they involve the multiplication symbol.</li>
<li>Is the optimal coefficient for carat, <span
class="math inline">w_1^*</span>, for this new prediction rule
guaranteed to be equal to 10000, the optimal coefficient for carat in
our original prediction rule? No justification is necessary.</li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-3">Problem 3</h2>
<p>The DataFrame <code>new_releases</code> contains the following
information for songs that were recently released:</p>
<ul>
<li><p><code>"genre"</code>: the genre of the song (one of the following
5 possibilities: <code>"Hip-Hop/Rap"</code>, <code>"Pop"</code>,
<code>"Country"</code>, <code>"Alternative"</code>, or
<code>"International"</code>)</p></li>
<li><p><code>"rec_label"</code>: the record label of the artist who
released the song (one of the following 4 possibilities:
<code>"EMI"</code>, <code>"SME"</code>, <code>"UMG"</code>, or
<code>"WMG"</code>)</p></li>
<li><p><code>"danceability"</code>: how easy the song is to dance to,
according to the Spotify API (between 0 and 1)</p></li>
<li><p><code>"speechiness"</code>: what proportion of the song is made
up of spoken words, according to the Spotify API (between 0 and
1)</p></li>
<li><p><code>"first_month"</code>: the number of total streams the song
had on Spotify in the first month it was released</p></li>
</ul>
<p>The first few rows of <code>new_releases</code> are shown below
(though <code>new_releases</code> has many more rows than are shown
below).</p>
<center><img src='../assets/images/disc09/new_releases.png' width=55%></center>
<p>We decide to build a linear regression model that predicts
<code>"first_month"</code> given all other information. To start, we
conduct a train-test split, splitting <code>new_releases</code> into
<code>X_train</code>, <code>X_test</code>, <code>y_train</code>, and
<code>y_test</code>.</p>
<p>We then fit two linear models (with intercept terms) to the training
data:</p>
<ul>
<li><p>Model 1 (<code>lr_one</code>): Uses <code>"danceability"</code>
only.</p></li>
<li><p>Model 2 (<code>lr_two</code>): Uses <code>"danceability"</code>
and <code>"speechiness"</code> only.</p></li>
</ul>
<p><br></p>
<h3 id="problem-3.1">Problem 3.1</h3>
<p>Consider the following outputs.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> X_train.shape[<span class="dv">0</span>]</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="dv">50</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> np.<span class="bu">sum</span>((y_train <span class="op">-</span> lr_two.predict(X_train)) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="dv">500000</span> <span class="co"># five hundred thousand</span></span></code></pre></div>
<p>What is Model 2 (<code>lr_two</code>)’s training RMSE? Give your
answer as an integer.</p>
<p><br></p>
<p>Now, suppose we fit two more linear models (with intercept terms) to
the training data:</p>
<ul>
<li><p>Model 3 (<span class="math inline">\texttt{lr\_drop}</span>):
Uses <code>"danceability"</code> and <code>"speechiness"</code> as-is,
and one-hot encodes <code>"genre"</code> and <code>"rec_label"</code>,
using <code>OneHotEncoder(drop="first")</code>.</p></li>
<li><p>Model 4 (<span class="math inline">\texttt{lr\_no\_drop}</span>):
Uses <code>"danceability"</code> and <code>"speechiness"</code> as-is,
and one-hot encodes <code>"genre"</code> and <code>"rec_label"</code>,
using <code>OneHotEncoder()</code>.</p></li>
</ul>
<p>Note that the only difference between Model 3 and Model 4 is the fact
that Model 3 uses <code>drop="first"</code>.</p>
<p><br></p>
<h3 id="problem-3.2">Problem 3.2</h3>
<p>How many <strong>one-hot encoded</strong> columns are used in each
model? In other words, how many <strong>binary</strong> columns are used
in each model? Give both answers as integers.</p>
<p><em>Hint: Make sure to look closely at the description of
<code>new_releases</code> at the top of the previous page, and don’t
include the already-quantitative features.</em></p>
<p>number of one-hot encoded columns in Model 3 (<code>lr_drop</code>)
=</p>
<p>number of one-hot encoded columns in Model 4
(<code>lr_no_drop</code>) =</p>
<p><br></p>
<h3 id="problem-3.3">Problem 3.3</h3>
<p>Recall, in Model 4 (<code>lr_no_drop</code>) we one-hot encoded
<code>"genre"</code> and <code>"rec_label"</code>, and did not use
<code>drop="first"</code> when instantiating our
<code>OneHotEncoder</code>.</p>
<p>Suppose we are given the following coefficients in Model 4:</p>
<ul>
<li><p>The coefficient on <code>"genre_Pop"</code> is <span
class="math inline">2000</span>.</p></li>
<li><p>The coefficient on <code>"genre_Country"</code> is <span
class="math inline">1000</span>.</p></li>
<li><p>The coefficient on <code>"danceability"</code> is <span
class="math inline">10^6 = 1{,}000{,}000</span>.</p></li>
</ul>
<p>Daisy and Billy are two artists signed to the same
<code>"rec_label"</code> who each just released a new song with the same
<code>"speechiness"</code>. Daisy is a <code>"Pop"</code> artist while
Billy is a <code>"Country"</code> artist.</p>
<p>Model 4 predicted that Daisy’s song and Billy’s song will have the
same <code>"first_month"</code> streams. What is the <strong>absolute
difference</strong> between Daisy’s song’s <code>"danceability"</code>
and Billy’s song’s <code>"danceability"</code>? Give your answer as a
simplified fraction.</p>
<p><br></p>
<hr />
<h2 id="problem-4">Problem 4</h2>
<p>Suppose we want to predict how long it takes to run a Jupyter
notebook on Datahub. For 100 different Jupyter notebooks, we collect the
following 5 pieces of information:</p>
<ul>
<li><p><strong>cells</strong>: number of cells in the notebook</p></li>
<li><p><strong>lines</strong>: number of lines of code</p></li>
<li><p><strong>max iterations</strong>: largest number of iterations in
any loop in the notebook, or 1 if there are no loops</p></li>
<li><p><strong>variables</strong>: number of variables defined in the
notebook</p></li>
<li><p><strong>runtime</strong>: number of seconds for the notebook to
run on Datahub</p></li>
</ul>
<p>Then we use multiple regression to fit a prediction rule of the form
<span class="math display">H(\text{cells, lines, max iterations,
variables}) =  w_0 + w_1 \cdot \text{cells} \cdot \text{lines} + w_2
\cdot (\text{max iterations})^{\text{variables} - 10}</span></p>
<p><br></p>
<h3 id="problem-4.1">Problem 4.1</h3>
<p>What are the dimensions of the design matrix <span
class="math inline">X</span>?</p>
<p><span class="math display">\begin{bmatrix}
&amp; &amp; &amp; \\
&amp; &amp; &amp; \\
&amp; &amp; &amp; \\
\end{bmatrix}_{r \times c}</span></p>
<p>So, what should <span class="math inline">r</span> and <span
class="math inline">c</span> be for: <span class="math inline">r</span>
rows <span class="math inline">\times</span> <span
class="math inline">c</span> columns.</p>
<p><br></p>
<h3 id="problem-4.2">Problem 4.2</h3>
<p>In <strong>one sentence</strong>, what does the entry in row 3,
column 2 of the design matrix X represent? (Count rows and columns
starting at 1, not 0).</p>
<p><br></p>
<hr />
<h2 id="problem-5">Problem 5</h2>
Now we solve the normal equations and find the solution to be
<span class="math display">\begin{aligned}
            \vec{w}^* &amp;= \begin{bmatrix} w_0^* \\ w_1^* \\ w_2^*
\end{bmatrix}
\end{aligned}</span>
Define a new vector:
<span class="math display">\begin{aligned}
            \vec{w}^{\circ} &amp;= \begin{bmatrix} w_0^{\circ} \\
w_1^{\circ} \\ w_2^{\circ} \end{bmatrix} = \begin{bmatrix} w_0^*+3 \\
w_1^*-4 \\ w_2^*-6 \end{bmatrix}
            
\end{aligned}</span>
<p>and consider the two prediction rules</p>
<span class="math display">\begin{aligned}
        H^*(\text{cells, lines, max iterations, variables})
&amp;=  w_0^* + w_1^* \cdot \text{cells} \cdot \text{lines} + w_2^*
\cdot (\text{max iterations})^{\text{variables} - 10}\\
        H^{\circ}(\text{cells, lines, max iterations, variables})
&amp;=  w_0^{\circ} + w_1^{\circ} \cdot \text{cells} \cdot \text{lines}
+ w_2^{\circ} \cdot (\text{max iterations})^{\text{variables} - 10}
        
\end{aligned}</span>
<p>Let <span class="math inline">\text{MSE}</span> represent the mean
squared error of a prediction rule, and let <span
class="math inline">\text{MAE}</span> represent the mean absolute error
of a prediction rule. Select the symbol that should go in each
blank.</p>
<p><br></p>
<h3 id="problem-5.1">Problem 5.1</h3>
<p><span class="math inline">\text{MSE}(H^*)</span> ___ <span
class="math inline">\text{MSE}(H^{\circ})</span></p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">\leq</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">\geq</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">=</span></p></li>
</ul>
<p><br></p>
<!-- Commented out this subproblem for now, solution is wack. To uncomment, highlight from "BEGIN SUBPROB" to "..other way around" -->
<!-- <br>

### Problem 5.2



$(\text{MAE}(H^{\circ}))^2$ ___ $\text{MSE}(H^{\circ})$

<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">\leq</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">\geq</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">=</span></p></li>
</ul>







    
<br> -->
<hr />
<h2 id="problem-6">Problem 6</h2>
<p>Let <span class="math inline">X</span> be a design matrix with 4
columns, such that the first column is a column of all <span
class="math inline">1</span>s. Let <span
class="math inline">\vec{y}</span> be an observation vector. Let <span
class="math inline">\vec{w}^* = (X^TX)^{-1}X^T\vec{y}.</span> We’ll name
the components of <span class="math inline">\vec{w}^*</span> as
follows:</p>
<p><span class="math display">\vec{w}^* = \begin{bmatrix} w_0^* \\ w_1^*
\\ w_2^* \\ w_3^* \end{bmatrix}</span></p>
<p>In this problem, we’ll consider various modifications to the design
matrix and see how they affect the solution to the normal equations.</p>
<p><br></p>
<h3 id="problem-6.1">Problem 6.1</h3>
<p>Let <span class="math inline">X_a</span> be the design matrix that
comes from <strong>interchanging the first two columns</strong> of <span
class="math inline">X</span>. Let <span class="math inline">\vec{w_a}^*
= (X_a^TX_a)^{-1}X_a^T\vec{y}</span>. Express the components <span
class="math inline">\vec{w_a}^*</span> in terms of <span
class="math inline">w_0^*, w_1^*, w_2^*</span>, and <span
class="math inline">w_3^*</span> (which were the components of <span
class="math inline">\vec{w}^*</span>).</p>
<p><br></p>
<p><br></p>
<h3 id="problem-6.2">Problem 6.2</h3>
<p>Let <span class="math inline">X_b</span> be the design matrix that
comes from <strong>adding one to each entry of the first column</strong>
of <span class="math inline">X</span>. Let <span
class="math inline">\vec{w_b}^* = (X_b^TX_b)^{-1}X_b^T\vec{y}</span>.
Express the components <span class="math inline">\vec{w_b}^*</span> in
terms of <span class="math inline">w_0^*, w_1^*, w_2^*</span>, and <span
class="math inline">w_3^*</span> (which were the components of <span
class="math inline">\vec{w}^*</span>).</p>
<p><br></p>
<p><br></p>
<h3 id="problem-6.3">Problem 6.3</h3>
<p>Let <span class="math inline">X_c</span> be the design matrix that
comes from <strong>adding one to each entry of the third column</strong>
of <span class="math inline">X</span>. Let <span
class="math inline">\vec{w_c}^* = (X_c^TX_c)^{-1}X_c^T\vec{y}</span>.
Express the components <span class="math inline">\vec{w_c}^*</span> in
terms of <span class="math inline">w_0^*, w_1^*, w_2^*</span>, and <span
class="math inline">w_3^*</span>, which were the components of <span
class="math inline">\vec{w}^*</span>.</p>
<p><br></p>
<hr />
<h2 id="problem-7">Problem 7</h2>
<p>The two plots below show the total number of boots (top) and sandals
(bottom) purchased per month in the <code>df</code> table. Assume that
there is one data point per month.</p>
<center><img src="../../assets/images/disc09/boot.png" style="width: 100%; height: auto;"></center>
<center><img src="../../assets/images/disc09/sandal.png" style="width: 100%; height: auto;"></center>
<p>For each of the following regression models, use the visualizations
shown above to select the value that is <strong>closest</strong> to the
fitted model weights. If it is not possible to determine the model
weight, select “Not enough info”. For the models below:</p>
<ul>
<li>The notation <code>boot</code> refers to the number of boots
sold.</li>
<li>The notation <code>sandal</code> refers to the number of sandals
sold.</li>
<li><code>summer=1</code> is a column with value 1 if the month is
between March (03) and August (08), inclusive.</li>
<li><code>winter=1</code> is a column with value 1 if the month is
between September (09) and February (02), inclusive.</li>
</ul>
<p><br></p>
<h3 id="problem-7.1">Problem 7.1</h3>
<p><code>boot</code> = w_0</p>
<p>w_0:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 50</p></li>
<li><p><input type="radio" disabled="" /> 100</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<p><br></p>
<h3 id="problem-7.2">Problem 7.2</h3>
<p><code>boot</code> = w_0 + w_1 </p>
<p>w_0:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -100</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 100</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p>w_1:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -100</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 100</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<p><br></p>
<h3 id="problem-7.3">Problem 7.3</h3>
<p><code>boot</code> = w_0 + w_1 ()</p>
<p>w_0:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -100</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 100</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p>w_1:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -80</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<p><br></p>
<h3 id="problem-7.4">Problem 7.4</h3>
<p><code>sandal</code> = ( w_0 + w_1 () )</p>
<p>w_0:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -20</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 20</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p>w_1:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -80</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<p><br></p>
<h3 id="problem-7.5">Problem 7.5</h3>
<p><code>sandal</code> = w_0 + w_1 () + w_2 ()</p>
<p>w_0:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -20</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 20</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p>w_1:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -80</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p>w_2:</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> -80</p></li>
<li><p><input type="radio" disabled="" /> -1</p></li>
<li><p><input type="radio" disabled="" /> 0</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 80</p></li>
<li><p><input type="radio" disabled="" /> Not enough info</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-8">Problem 8</h2>
<p>Consider a dataset of <span class="math inline">n</span> values,
<span class="math inline">y_1, y_2, ..., y_n</span>, where <span
class="math inline">y_1 &lt; y_2 &lt; ... &lt; y_n</span>. Let <span
class="math inline">R_\text{abs}(h)</span> be the mean absolute error of
a constant prediction <span class="math inline">h</span> on this dataset
of <span class="math inline">n</span> values.</p>
<p>Suppose that we introduce a new value to the dataset, <span
class="math inline">\alpha</span>. Let <span
class="math inline">S_\text{abs}(h)</span> be the mean absolute error of
a constant prediction <span class="math inline">h</span> on this new
dataset of <span class="math inline">n + 1</span> values.</p>
<p>We’re given that:</p>
<ul>
<li><span class="math inline">n &gt; 5</span></li>
<li><span class="math inline">\alpha</span> is not equal to any of <span
class="math inline">y_1, y_2, ..., y_n</span>.</li>
<li>All values of <span class="math inline">h</span> between 7 and 9
minimize <span class="math inline">S_\text{abs}(h)</span>.</li>
<li>The slope of <span class="math inline">S_\text{abs}(h)</span> on the
line segment immediately to the right of <span
class="math inline">\alpha</span> is <span
class="math inline">\frac{5-n}{1 + n}</span>.</li>
</ul>
<p><br></p>
<h3 id="problem-8.1">Problem 8.1</h3>
<p>In the problem statement, we were told that ``all values between 7
and 9 minimize <span class="math inline">S_\text{abs}(h)</span>.” More
specifically, what interval of values <span class="math inline">h</span>
minimize <span class="math inline">S_\text{abs}(h)</span>?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">7 &lt; h &lt; 9</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">7 \leq h &lt; 9</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">7 &lt; h \leq 9</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">7 \leq h \leq 9</span></p></li>
</ul>
<p><br></p>
<h3 id="problem-8.2">Problem 8.2</h3>
<p>Which value(s) minimize <span
class="math inline">R_\text{abs}(h)</span>? Give your answer(s) as
integer(s) with no variables. Show your work.</p>
<p><i>Hint: Don’t start by trying to expand <span
class="math inline">\frac{1}{n} \sum_{i = 1}^n |y_i - h|</span> —
instead, think about what removing <span
class="math inline">\alpha</span> does.</i></p>
<p><br></p>
<h3 id="problem-8.3">Problem 8.3</h3>
<p>What is the slope of <span class="math inline">S_\text{abs}(h)</span>
on the line segment immediately to the left of <span
class="math inline">\alpha</span>? Give your answer in the form of an
expression involving <span class="math inline">n</span>. Show your
work.</p>
<p><br></p>
<hr />
<h2 id="problem-9">Problem 9</h2>
<p>Consider the dataset shown below.</p>
<div class="center">
<table>
<thead>
<tr>
<th style="text-align: left;"><span
class="math inline">x^{(1)}</span></th>
<th style="text-align: left;"><span
class="math inline">x^{(2)}</span></th>
<th style="text-align: left;"><span
class="math inline">x^{(3)}</span></th>
<th style="text-align: left;"><span class="math inline">y</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">0</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">-5</td>
</tr>
<tr>
<td style="text-align: left;">3</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">7</td>
</tr>
<tr>
<td style="text-align: left;">5</td>
<td style="text-align: left;">-1</td>
<td style="text-align: left;">-3</td>
<td style="text-align: left;">4</td>
</tr>
<tr>
<td style="text-align: left;">0</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">2</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<h3 id="problem-9.1">Problem 9.1</h3>
<p>We want to use multiple regression to fit a prediction rule of the
form <span class="math display">H(x^{(1)}, x^{(2)}, x^{(3)}) = w_0 + w_1
x^{(1)}x^{(3)} + w_2 (x^{(2)}-x^{(3)})^2.</span> Write down the design
matrix <span class="math inline">X</span> and observation vector <span
class="math inline">\vec{y}</span> for this scenario. No justification
needed.</p>
<p><br></p>
<h3 id="problem-9.2">Problem 9.2</h3>
<p>For the <span class="math inline">X</span> and <span
class="math inline">\vec{y}</span> that you have written down, let <span
class="math inline">\vec{w}</span> be the optimal parameter vector,
which comes from solving the normal equations <span
class="math inline">X^TX\vec{w}=X^T\vec{y}</span>. Let <span
class="math inline">\vec{e} = \vec{y} - X \vec{w}</span> be the error
vector, and let <span class="math inline">e_i</span> be the <span
class="math inline">i</span>th component of this error vector. Show that
<span class="math display">4e_1+e_2+4e_3+e_4=0.</span></p>
<p><br></p>
<hr />
<h2 id="problem-10">Problem 10</h2>
<!-- Regression Question -->
<p>Reggie and Essie are given a dataset of real features <span
class="math inline">x_i \in \mathbb{R}</span> and observations <span
class="math inline">y_i</span>. Essie proposes the following linear
prediction rule: <span class="math display">H_1(\alpha_0,\alpha_1) =
\alpha_0 + \alpha_1 x_i.</span> and Reggie proposes to use <span
class="math inline">v_i=(x_i)^2</span> and the prediction rule <span
class="math display">H_2(\gamma_0,\gamma_1) = \gamma_0 + \gamma_1
v_i.</span></p>
<p><br></p>
<h3 id="problem-10.1">Problem 10.1</h3>
<p>Give an example of a dataset <span
class="math inline">\{(x_i,y_i)\}_{i=1}^n</span> for which minimum
MSE<span class="math inline">(H_2) &lt;</span> minimum MSE<span
class="math inline">(H_1)</span>. Explain.</p>
<p><br></p>
<h3 id="problem-10.2">Problem 10.2</h3>
<p>Give an example of a dataset <span
class="math inline">\{(x_i,y_i)\}_{i=1}^n</span> for which minimum
MSE<span class="math inline">(H_2) =</span> minimum MSE<span
class="math inline">(H_1)</span>. Explain.</p>
<p><br></p>
<h3 id="problem-10.3">Problem 10.3</h3>
<p>A new feature <span class="math inline">z</span> has been added to
the dataset.</p>
<p>Essie proposes a linear regression model using two predictor
variables <span class="math inline">x,z</span> as <span
class="math display">H_3(w_0,w_1,w_2) = w_0 + w_1 x_i +w_2
z_i.</span></p>
<p>Explain if the following statement is <strong>True or False</strong>
(prove or provide counter-example).</p>
<p>Reggie claims that having more features will lead to a smaller error,
therefore the following prediction rule will give a smaller MSE: <span
class="math display">H_4(\alpha_0,\alpha_1,\alpha_2,\alpha_3) = \alpha_0
+ \alpha_1 x_i +\alpha_2 z_i + \alpha_3 (2x_i-z_i)</span></p>
<p><br></p>
<hr />
<h2 id="problem-11">Problem 11</h2>
<p>One piece of information that may be useful as a feature is the
proportion of SAT test takers in a state in a given year that qualify
for free lunches in school. The Series <code>lunch_props</code> contains
8 values, each of which are either <code>"low"</code>,
<code>"medium"</code>, or <code>"high"</code>. Since we can’t use
strings as features in a model, we decide to encode these strings using
the following <code>Pipeline</code>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: The FunctionTransformer is only needed to change the result</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># of the OneHotEncoder from a &quot;sparse&quot; matrix to a regular matrix</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># so that it can be used with StandardScaler;</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># it doesn&#39;t change anything mathematically.</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>pl <span class="op">=</span> Pipeline([</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;ohe&quot;</span>, OneHotEncoder(drop<span class="op">=</span><span class="st">&quot;first&quot;</span>)),</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;ft&quot;</span>, FunctionTransformer(<span class="kw">lambda</span> X: X.toarray())),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;ss&quot;</span>, StandardScaler())</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div>
<p>After calling <code>pl.fit(lunch_props)</code>,
<code>pl.transform(lunch_props)</code> evaluates to the following
array:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>array([[ <span class="fl">1.29099445</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>,  <span class="fl">2.64575131</span>],</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>       [ <span class="fl">1.29099445</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>       [ <span class="fl">1.29099445</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>, <span class="op">-</span><span class="fl">0.37796447</span>]])</span></code></pre></div>
<p>and <code>pl.named_steps["ohe"].get_feature_names()</code> evaluates
to the following array:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>array([<span class="st">&quot;x0_low&quot;</span>, <span class="st">&quot;x0_med&quot;</span>], dtype<span class="op">=</span><span class="bu">object</span>)</span></code></pre></div>
<p>Fill in the blanks: Given the above information, we can conclude that
<code>lunch_props</code> has <strong>(a)</strong> value(s) equal to
<code>"low"</code>, <strong>(b)</strong> value(s) equal to
<code>"medium"</code>, and <strong>(c)</strong> value(s) equal to
<code>"high"</code>. <em>(Note: You should write one positive integer in
each box such that the numbers add up to 8.)</em></p>
<p>What goes in the blanks?</p>
<hr />
<h2 id="problem-12">Problem 12</h2>
<p>Jasmine and Aritra are trying to build models that predict the number
of open rooms a hotel room has. To do so, they use <code>price</code>,
the average listing price of rooms at the hotel, along with a one hot
encoded version of the hotel’s <code>chain</code>. <strong>For the
purposes of this question, assume the only possible hotel chains are
Marriott, Hilton, and Other.</strong></p>
<p><br></p>
<h3 id="problem-12.1">Problem 12.1</h3>
<p>First, Jasmine fits a linear model <em>without</em> an intercept
term. Her prediction rule, <span class="math inline">H_1</span>, looks
like:</p>
<p><span class="math display">H_{1}(x) = w_1 \cdot \texttt{price} + w_2
\cdot \texttt{is\_Marriott} + w_3 \cdot \texttt{is\_Hilton} + w_4 \cdot
\texttt{is\_Other}</span></p>
<p>After fitting her model, <span class="math inline">\vec{w}^* =
\begin{bmatrix}−0.5 \\ 200 \\ 300 \\ 50 \end{bmatrix}</span>.</p>
<ol type="1">
<li>The Marriott Marquis San Diego Marina, a hotel in the Marriott
chain, has an average listing price of $250. How many open rooms does
<span class="math inline">H_1</span> predict it has? Give your answer as
a number with no variables.</li>
<li>The Marriott Marquis San Diego Marina actually has 45 open rooms.
What’s the squared loss of your prediction above? Give your answer as a
number with no variables.</li>
<li>True or False: Because your answer to (ii) above is not 0, it means
there were no hotels in the Marriott chain with an average listing price
of $250 in the training set. d ( ) True ( ) False</li>
</ol>
<p><br></p>
<h3 id="problem-12.2">Problem 12.2</h3>
<p>As a reminder,</p>
<p><span class="math display">H_{1}(x) = w_1 \cdot \texttt{price} + w_2
\cdot \texttt{is\_Marriott} + w_3 \cdot \texttt{is\_Hilton} + w_4 \cdot
\texttt{is\_Other}</span></p>
<p><span class="math display">\vec{w}^* = \begin{bmatrix}−0.5 \\ 200 \\
300 \\ 50 \end{bmatrix}</span></p>
<p><span class="math display">H_2(x) = \beta_0 + \beta_1 \cdot
\texttt{price} + \beta_2 \cdot \texttt{is\_Marriott} + \beta_3 \cdot
\texttt{is\_Hilton}</span></p>
<p>After fitting his model, Aritra finds <span
class="math inline">\beta_{0}^{*} = 50.</span> Given that, what are
<span class="math inline">\beta_{1}^{*}</span>, <span
class="math inline">\beta_{2}^{*}</span>, and <span
class="math inline">\beta_{3}^{*}</span>? Give your answers as numbers
with no variables.</p>
<p><br></p>
<hr />
<h2 id="section"><span class="math display"> </span></h2>
<h4
id="feedback-find-an-error-still-confused-have-a-suggestion-let-us-know-here.">👋
Feedback: Find an error? Still confused? Have a suggestion? Let us know
<a href="https://forms.gle/xK4DpWXh9rq8AKP37">here</a>.</h4>
<hr />
</body>
</html>
