<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Final Review: Post-Midterm Content</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../assets/theme.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Final Review: Post-Midterm Content</h1>
</header>
<p><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
<!-- add after bootstrap.min.css -->
<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css"/>
<!-- add after bootstrap.min.js or bootstrap.bundle.min.js -->
<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script></p>
<!-- for difficulty gauges-->
<script src="https://cdn.plot.ly/plotly-2.16.1.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-B947E6J6H4"></script> -->
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  // gtag('js', new Date());

  // gtag('config', 'G-B947E6J6H4');
</script>
<p><a href="../index.html">← return to study.practicaldsc.org</a></p>
<hr />
<p>The problems in this worksheet are taken from past exams in similar
classes. Work on them <strong>on paper</strong>, since the exams you
take in this course will also be on paper. <br><br>We encourage you to
attempt these problems <strong>before</strong> Tuesday’s exam review
session, so that we have enough time to walk through the solutions to
all of the problems. <br><br>We will enable the solutions here after the
review session, though you can find the written solutions to these
problems in other discussion worksheets.</p>
<hr />
<h2 id="problem-1">Problem 1</h2>
<p>Consider a dataset of <span class="math inline">n</span> values,
<span class="math inline">y_1, y_2, ..., y_n</span>, all of which are
non-negative. We’re interested in fitting a constant model, <span
class="math inline">H(x) = h</span>, to the data, using the new
“Wolverine” loss function:</p>
<p><span class="math display">L_\text{wolverine}(y_i, h) = w_i \left(
y_i^2 - h^2  \right)^2</span></p>
<p>Here, <span class="math inline">w_i</span> corresponds to the
“weight” assigned to the data point <span
class="math inline">y_i</span>, the idea being that different data
points can be weighted differently when finding the optimal constant
prediction, <span class="math inline">h^*</span>.</p>
<p>For example, for the dataset <span class="math inline">y_1 = 1, y_2 =
5, y_3 = 2</span>, we will end up with different values of <span
class="math inline">h^*</span> when we use the weights <span
class="math inline">w_1 = w_2 = w_3 = 1</span> and when we use weights
<span class="math inline">w_1 = 8, w_2 = 4, w_3 = 3</span>.</p>
<p><br></p>
<h3 id="problem-1.1">Problem 1.1</h3>
<p>Find <span class="math inline">\frac{\partial
L_\text{wolverine}}{\partial h}</span>, the derivative of the Wolverine
loss function with respect to <span class="math inline">h</span>. Show
your work.</p>
<p><br></p>
<h3 id="problem-1.2">Problem 1.2</h3>
<p>Prove that the constant prediction that minimizes average loss for
the Wolverine loss function is:</p>
<p><span class="math display">h^* = \sqrt{\frac{\sum_{i = 1}^n w_i
y_i^2}{\sum_{i = 1}^n w_i}}</span></p>
<p><br></p>
<h3 id="problem-1.3">Problem 1.3</h3>
<p>For a dataset of non-negative values <span class="math inline">y_1,
y_2, ..., y_n</span> with weights <span class="math inline">w_1, 1, ...,
1</span>, evaluate: <span class="math display">\displaystyle \lim_{w_1
\rightarrow \infty} h^*</span></p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> The maximum of <span class="math inline">y_1, y_2, ...,
y_n</span></p></li>
<li><p><input type="radio" disabled="" /> The mean of <span class="math inline">y_1, y_2, ...,
y_{n-1}</span></p></li>
<li><p><input type="radio" disabled="" /> The mean of <span class="math inline">y_2, y_3, ..., y_n</span></p></li>
<li><p><input type="radio" disabled="" /> The mean of <span class="math inline">y_2, y_3, ..., y_n</span>,
multiplied by <span class="math inline">\frac{n}{n-1}</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">y_1</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">y_n</span></p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-2">Problem 2</h2>
<p>Suppose we want to fit a hypothesis function of the form:</p>
<p><span class="math display">H(x) = w_0 + w_1 x^2</span></p>
<p>Note that this is <em>not</em> the simple linear regression
hypothesis function, <span class="math inline">H(x) = w_0 +
w_1x</span>.</p>
<p>To do so, we will find the optimal parameter vector <span
class="math inline">\vec{w}^* = \begin{bmatrix} w_0^* \\ w_1^*
\end{bmatrix}</span> that satisfies the normal equations. The first 5
rows of our dataset are as follows, though note that our dataset has
<span class="math inline">n</span> rows in total.</p>
<!-- | x  | y |
|----|---|
| 2  | 4 |
| -1 | 4 |
| 3  | 4 |
| -7 | 4 |
| 3  | 4 | -->
<table style="border: 1px solid black; border-collapse: collapse; margin: auto; text-align: center;">
  <tr>
    <th style="border: 1px solid black; padding: 8px;">x</th>
    <th style="border: 1px solid black; padding: 8px;">y</th>
  </tr>
  <tr>
    <td style="border: 1px solid black; padding: 8px;">2</td>
    <td style="border: 1px solid black; padding: 8px;">4</td>
  </tr>
  <tr>
    <td style="border: 1px solid black; padding: 8px;">-1</td>
    <td style="border: 1px solid black; padding: 8px;">4</td>
  </tr>
  <tr>
    <td style="border: 1px solid black; padding: 8px;">3</td>
    <td style="border: 1px solid black; padding: 8px;">4</td>
  </tr>
  <tr>
    <td style="border: 1px solid black; padding: 8px;">-7</td>
    <td style="border: 1px solid black; padding: 8px;">4</td>
  </tr>
  <tr>
    <td style="border: 1px solid black; padding: 8px;">3</td>
    <td style="border: 1px solid black; padding: 8px;">4</td>
  </tr>
</table>
<p>Suppose that <span class="math inline">x_1, x_2, ..., x_n</span> have
a mean of <span class="math inline">\bar{x} = 2</span> and a variance of
<span class="math inline">\sigma_x^2 = 10</span>.</p>
<p><br></p>
<h3 id="problem-2.1">Problem 2.1</h3>
<p>Write out the first 5 rows of the design matrix, <span
class="math inline">X</span>.</p>
<p><br></p>
<h3 id="problem-2.2">Problem 2.2</h3>
<p>Suppose, just in part (b), that after solving the normal equations,
we find <span class="math inline">\vec{w}^* = \begin{bmatrix} 2 \\ -5
\end{bmatrix}</span>. What is the predicted <span
class="math inline">y</span> value for <span class="math inline">x =
2</span>? Give your answer as an integer with no variables. Show your
work.</p>
<p><br></p>
<h3 id="problem-2.3">Problem 2.3</h3>
<p>Let <span class="math inline">X_\text{tri} = 3 X</span>. Using the
fact that <span class="math inline">\sum_{i = 1}^n x_i^2 = n \sigma_x^2
+ n \bar{x}^2</span>, determine the value of the bottom-left value in
the matrix <span class="math inline">X_\text{tri}^T X_\text{tri}</span>,
i.e. the value in the second row and first column. Give your answer as
an expression involving <span class="math inline">n</span>. Show your
work.</p>
<p><br></p>
<hr />
<h2 id="problem-3">Problem 3</h2>
<p>Suppose we have one qualitative variable that that we convert to
numerical values using one- hot encoding. We’ve shown the first four
rows of the resulting design matrix below:</p>
<center><img src='../assets/images/disc10/matrix.png' width=400></center>
<p><br></p>
<h3 id="problem-3.1">Problem 3.1</h3>
<p>Say we train a linear model <span class="math inline">m_1</span> on
these data. Then, we replace all of the 1 values in column
<strong>a</strong> with 3’s and all of the 1 values in column
<strong>b</strong> with 2’s and train a new linear model <span
class="math inline">m_2</span>. Neither <span
class="math inline">m_1</span> nor <span class="math inline">m_2</span>
have an intercept term. On the training data, the average squared loss
for <span class="math inline">m_1</span> will be ________ that of <span
class="math inline">m_2</span>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> greater than</p></li>
<li><p><input type="radio" disabled="" /> less than</p></li>
<li><p><input type="radio" disabled="" /> equal to</p></li>
<li><p><input type="radio" disabled="" /> impossible to tell</p></li>
</ul>
<p><br></p>
<h3 id="problem-3.2">Problem 3.2</h3>
<p>To account for the intercept term, we add a column of all ones to our
design matrix from part a. That is, the resulting design matrix has four
columns: <strong>a</strong> with 3’s instead of 1’s, <strong>b</strong>
with 2’s instead of 1’s, <strong>c</strong>, and a column of all ones.
What is the rank of the new design matrix with these four columns?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 2</p></li>
<li><p><input type="radio" disabled="" /> 3</p></li>
<li><p><input type="radio" disabled="" /> 4</p></li>
</ul>
<p><br></p>
<h3 id="problem-3.3">Problem 3.3</h3>
<p>Suppose we divide our sampling frame into three clusters of people,
numbered 1, 2, and 3. After we survey people, along with our survey
results, we save their cluster number as a new feature in our design
matrix. Before training a model, what should we do with the cluster
column? (Note: This part is independent of parts a and b.)</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Leave as is</p></li>
<li><p><input type="radio" disabled="" /> One-hot encode it</p></li>
<li><p><input type="radio" disabled="" /> Normalize it</p></li>
<li><p><input type="radio" disabled="" /> Use bag of words</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-4">Problem 4</h2>
<p>One piece of information that may be useful as a feature is the
proportion of SAT test takers in a state in a given year that qualify
for free lunches in school. The Series <code>lunch_props</code> contains
8 values, each of which are either <code>"low"</code>,
<code>"medium"</code>, or <code>"high"</code>. Since we can’t use
strings as features in a model, we decide to encode these strings using
the following <code>Pipeline</code>:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: The FunctionTransformer is only needed to change the result</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># of the OneHotEncoder from a &quot;sparse&quot; matrix to a regular matrix</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># so that it can be used with StandardScaler;</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># it doesn&#39;t change anything mathematically.</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>pl <span class="op">=</span> Pipeline([</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;ohe&quot;</span>, OneHotEncoder(drop<span class="op">=</span><span class="st">&quot;first&quot;</span>)),</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;ft&quot;</span>, FunctionTransformer(<span class="kw">lambda</span> X: X.toarray())),</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;ss&quot;</span>, StandardScaler())</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div>
<p>After calling <code>pl.fit(lunch_props)</code>,
<code>pl.transform(lunch_props)</code> evaluates to the following
array:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>array([[ <span class="fl">1.29099445</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>,  <span class="fl">2.64575131</span>],</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>       [ <span class="fl">1.29099445</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>       [ <span class="fl">1.29099445</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>, <span class="op">-</span><span class="fl">0.37796447</span>],</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.77459667</span>, <span class="op">-</span><span class="fl">0.37796447</span>]])</span></code></pre></div>
<p>and <code>pl.named_steps["ohe"].get_feature_names()</code> evaluates
to the following array:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>array([<span class="st">&quot;x0_low&quot;</span>, <span class="st">&quot;x0_med&quot;</span>], dtype<span class="op">=</span><span class="bu">object</span>)</span></code></pre></div>
<p>Fill in the blanks: Given the above information, we can conclude that
<code>lunch_props</code> has <strong>(a)</strong> value(s) equal to
<code>"low"</code>, <strong>(b)</strong> value(s) equal to
<code>"medium"</code>, and <strong>(c)</strong> value(s) equal to
<code>"high"</code>. <em>(Note: You should write one positive integer in
each box such that the numbers add up to 8.)</em></p>
<p>What goes in the blanks?</p>
<hr />
<h2 id="problem-5">Problem 5</h2>
<p>Consider the least squares regression model, <span
class="math inline">\vec{h} = X \vec{w}</span>. Assume that <span
class="math inline">X</span> and <span
class="math inline">\vec{h}</span> refer to the design matrix and
hypothesis vector for our training data, and <span
class="math inline">\vec y</span> is the true observation vector.</p>
<p>Let <span class="math inline">\vec{w}_\text{OLS}^*</span> be the
parameter vector that minimizes mean squared error without
regularization. Specifically:</p>
<p><span class="math inline">\vec{w}_\text{OLS}^*</span> = <span
class="math inline">\arg\underset{\vec{w}}{\min} \frac{1}{n} \| \vec{y}
- X \vec{w} \|^2_2</span></p>
<p>Let <span class="math inline">\vec{w}_\text{ridge}^*</span> be the
parameter vector that minimizes mean squared error with <span
class="math inline">L_2</span> regularization, using a non-negative
regularization hyperparameter <span class="math inline">\lambda</span>
(i.e. ridge regression). Specifically:</p>
<p><span class="math inline">\vec{w}_\text{ridge}^*</span> = <span
class="math inline">\arg\underset{\vec{w}}{\min} \frac{1}{n} \| \vec y -
X \vec{w} \|^2_2 + \lambda \sum_{j=1}^{p} w_j^2</span></p>
<p>For each of the following problems, fill in the blank.</p>
<p><br></p>
<h3 id="problem-5.1">Problem 5.1</h3>
<p>If we set <span class="math inline">\lambda</span> = 0, then <span
class="math inline">\Vert \vec{w}_\text{OLS}^* \Vert^2_2</span> is
<strong>____</strong> <span class="math inline">\Vert
\vec{w}_\text{ridge}^* \Vert^2_2</span></p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> less than</p></li>
<li><p><input type="radio" disabled="" /> equal to</p></li>
<li><p><input type="radio" disabled="" /> greater than</p></li>
<li><p><input type="radio" disabled="" /> impossible to tell</p></li>
</ul>
<p><br></p>
<h3 id="problem-5.2">Problem 5.2</h3>
<p>For each of the remaining parts, you can assume that <span
class="math inline">\lambda</span> is set such that the predicted
response vectors for our two models (<span class="math inline">\vec{h} =
X \vec{w}_\text{OLS}^*</span> and <span class="math inline">\vec{h} = X
\vec{w}_\text{ridge}^*</span>) is different.</p>
<p>The <strong>training</strong> MSE of the model <span
class="math inline">\vec{h} = X \vec{w}_\text{OLS}^*</span> is
<strong>____</strong> than the model <span class="math inline">\vec{h} =
X \vec{w}_\text{ridge}^*</span>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> less than</p></li>
<li><p><input type="radio" disabled="" /> equal to</p></li>
<li><p><input type="radio" disabled="" /> greater than</p></li>
<li><p><input type="radio" disabled="" /> impossible to tell</p></li>
</ul>
<p><br></p>
<h3 id="problem-5.3">Problem 5.3</h3>
<p>Now, assume we’ve fit both models using our training data, and
evaluate both models on some unseen testing data.</p>
<p>The <strong>test</strong> MSE of the model <span
class="math inline">\vec{h} = X \vec{w}_\text{OLS}^*</span> is
<strong>____</strong> than the model <span class="math inline">\vec{h} =
X \vec{w}_\text{ridge}^*</span>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> less than</p></li>
<li><p><input type="radio" disabled="" /> equal to</p></li>
<li><p><input type="radio" disabled="" /> greater than</p></li>
<li><p><input type="radio" disabled="" /> impossible to tell</p></li>
</ul>
<p><br></p>
<h3 id="problem-5.4">Problem 5.4</h3>
<p>Assume that our design matrix <span class="math inline">X</span>
contains a column of all ones. The sum of the residuals of our model
<span class="math inline">\vec{h} = X \vec{w}_\text{ridge}^*</span>
<strong>____</strong>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> equal to 0</p></li>
<li><p><input type="radio" disabled="" /> not necessarily equal to 0</p></li>
</ul>
<p><br></p>
<h3 id="problem-5.5">Problem 5.5</h3>
<p>As we increase <span class="math inline">\lambda</span>, the bias of
the model <span class="math inline">\vec{h} = X
\vec{w}_\text{ridge}^*</span> tends to <strong>____</strong>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> increase</p></li>
<li><p><input type="radio" disabled="" /> stay the same</p></li>
<li><p><input type="radio" disabled="" /> decrease</p></li>
</ul>
<p><br></p>
<h3 id="problem-5.6">Problem 5.6</h3>
<p>As we increase <span class="math inline">\lambda</span>, the model
variance of the model <span class="math inline">\vec{h} = X
\vec{w}_\text{ridge}^*</span> tends to <strong>____</strong>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> increase</p></li>
<li><p><input type="radio" disabled="" /> stay the same</p></li>
<li><p><input type="radio" disabled="" /> decrease</p></li>
</ul>
<p><br></p>
<h3 id="problem-5.7">Problem 5.7</h3>
<p>As we increase <span class="math inline">\lambda</span>, the
observation variance of the model <span class="math inline">\vec{h} = X
\vec{w}_\text{ridge}^*</span> tends to <strong>____</strong>.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> increase</p></li>
<li><p><input type="radio" disabled="" /> stay the same</p></li>
<li><p><input type="radio" disabled="" /> decrease</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-6">Problem 6</h2>
<p>Neerad wants to build a model that predicts the number of open rooms
a hotel has, given various other features. He has a training set with
1200 rows available to him for the purposes of training his model.</p>
<p><br></p>
<h3 id="problem-6.1">Problem 6.1</h3>
<p>Neerad fits a regression model using the <code>GPTRegression</code>
class. <code>GPTRegression</code> models have several hyperparameters
that can be tuned, including <code>context_length</code> and
<code>sentience</code>.</p>
<p>To choose between 5 possible values of the hyperparameter
<code>context_length</code>, Neerad performs <span
class="math inline">k</span>-fold cross-validation.</p>
<ol type="1">
<li>How many total times is a <code>GPTRegression</code> model fit?</li>
</ol>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">4k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">5k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">240k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">6000k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">4(k − 1)</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">5(k − 1)</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">240(k − 1)</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">6000(k − 1)</span></p></li>
</ul>
<ol start="2" type="1">
<li>Suppose that every time a <code>GPTRegression</code> model is fit,
it appends the number of points in its training set to the list
<code>sizes</code>. Note that after performing cross- validation,
<code>len(sizes)</code> is equal to your answer to the previous
subpart.</li>
</ol>
<p>What is <code>sum(sizes)</code>?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">4k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">5k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">240k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">6000k</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">4(k − 1)</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">5(k − 1)</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">240(k − 1)</span></p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">6000(k − 1)</span></p></li>
</ul>
<p><br></p>
<h3 id="problem-6.2">Problem 6.2</h3>
<p>The average training error and validation error for all 5 candidate
values of <code>context_length</code> are given below.</p>
<center><img src="../../assets/images/disc10/validation.png" width=600></center>
<p>Fill in the blanks: As <code>context_length</code> increases, model
complexity <code>__(i)__</code>. The optimal choice of
<code>context_length</code> is <code>__(ii)__</code>; if we choose a
<code>context_length</code> any higher than that, our model will
<code>__(iii)__</code>.</p>
<ol type="1">
<li>What goes in blank (i)?</li>
</ol>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> increases</p></li>
<li><p><input type="radio" disabled="" /> decreases</p></li>
</ul>
<ol start="2" type="1">
<li>What goes in blank (ii)?</li>
</ol>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> 0.1</p></li>
<li><p><input type="radio" disabled="" /> 1</p></li>
<li><p><input type="radio" disabled="" /> 10</p></li>
<li><p><input type="radio" disabled="" /> 100</p></li>
<li><p><input type="radio" disabled="" /> 1000</p></li>
</ul>
<ol start="3" type="1">
<li>What goes in blank (iii)?</li>
</ol>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> overfit the training data and have high bias</p></li>
<li><p><input type="radio" disabled="" /> underfit the training data and have high bias</p></li>
<li><p><input type="radio" disabled="" /> overfit the training data and have low bias</p></li>
<li><p><input type="radio" disabled="" /> underfit the training data and have low bias</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-7">Problem 7</h2>
<p>Suppose we want to use logistic regression to classify whether a
person survived the sinking of the Titanic. The first 5 rows of our
dataset are given below.</p>
<p><span class="math display">\begin{array}{|c|c|c|c|}
\hline
&amp; \textbf{Age} &amp; \textbf{Survived} &amp; \textbf{Female} \\
\hline
0 &amp; 22.0 &amp; 0 &amp; 0 \\ \hline
1 &amp; 38.0 &amp; 1 &amp; 1 \\ \hline
2 &amp; 26.0 &amp; 1 &amp; 1 \\ \hline
3 &amp; 35.0 &amp; 1 &amp; 1 \\ \hline
4 &amp; 35.0 &amp; 0 &amp; 0 \\ \hline
\end{array}</span></p>
<p>Suppose after training our logistic regression model we get <span
class="math inline">\vec{w}^* = \begin{bmatrix}
-1.2 \\ -0.005 \\ 2.5
\end{bmatrix}</span>, where <span class="math inline">-1.2</span> is an
intercept term, <span class="math inline">-0.005</span> is the optimal
parameter corresponding to passenger’s age, and <span
class="math inline">2.5</span> is the optimal parameter corresponding to
sex (1 if female, 0 otherwise).</p>
<p><br></p>
<h3 id="problem-7.1">Problem 7.1</h3>
<p>Consider Sı̄lānah Iskandar Nāsı̄f Abı̄ Dāghir Yazbak, a 20 year old
female. What chance did she have to survive the sinking of the Titanic
according to our model? Give your answer as a probability in terms of
<span class="math inline">\sigma</span>. If there is not enough
information, write “not enough information.”</p>
<p><br></p>
<h3 id="problem-7.2">Problem 7.2</h3>
<p>Sı̄lānah Iskandar Nāsı̄f Abı̄ Dāghir Yazbak actually survived. What is
the cross-entropy loss for our prediction in the previous part?</p>
<p><br></p>
<h3 id="problem-7.3">Problem 7.3</h3>
<p>At what age would we predict that a female passenger is more likely
to have survived the Titanic than not? In other words, at what age is
the probability of survival for a female passenger greater than 0.5?</p>
<p><em>Hint: Since <span class="math inline">\sigma(0) = 0.5</span>, we
have that <span class="math inline">\sigma \left( \vec{w}^* \cdot
\text{Aug}(\vec x) \right) = 0.5 \implies \vec{w}^* \cdot
\text{Aug}(\vec x) = 0</span>.</em></p>
<p><br></p>
<h3 id="problem-7.4">Problem 7.4</h3>
<p>Let <span class="math inline">m</span> be the <strong>odds</strong>
of a given non-female passenger’s survival according to our logistic
regression model, i.e., if the passenger had an 80% chance of survival,
<span class="math inline">m</span> would be 4, since their odds of
survival are <span class="math inline">\frac{0.8}{0.2} = 4</span>.</p>
<p>It turns out we can compute <span class="math inline">f</span>, the
odds of survival for a female passenger of the same age, in terms of
<span class="math inline">m</span>. Give an expression for <span
class="math inline">f</span> in terms of <span
class="math inline">m</span>.</p>
<p><br></p>
<hr />
<h2 id="problem-8">Problem 8</h2>
<p>We decide to build a classifier that takes in a state’s demographic
information and predicts whether, in a given year:</p>
<ul>
<li><p>The state’s mean math score was greater than its mean verbal
score (1), or</p></li>
<li><p>the state’s mean math score was less than or equal to its mean
verbal score (0).</p></li>
</ul>
<p><br></p>
<h3 id="problem-8.1">Problem 8.1</h3>
<p>The simplest possible classifier we could build is one that predicts
the same label (1 or 0) every time, independent of all other
features.</p>
<p>Consider the following statement:</p>
<p><em>If <code>a &gt; b</code>, then the constant classifier that
maximizes training accuracy predicts 1 every time; otherwise, it
predicts 0 every time.</em></p>
<p>For which combination of <code>a</code> and <code>b</code> is the
above statement <strong>not guaranteed</strong> to be true?</p>
<p><em>Note: Treat <code>sat</code> as our training set.</em></p>
<p>Option 1:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> (sat[<span class="st">&#39;Math&#39;</span>] <span class="op">&gt;</span> sat[<span class="st">&#39;Verbal&#39;</span>]).mean()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
<p>Option 2:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> (sat[<span class="st">&#39;Math&#39;</span>] <span class="op">-</span> sat[<span class="st">&#39;Verbal&#39;</span>]).mean()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
<p>Option 3:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> (sat[<span class="st">&#39;Math&#39;</span>] <span class="op">-</span> sat[<span class="st">&#39;Verbal&#39;</span>] <span class="op">&gt;</span> <span class="dv">0</span>).mean()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
<p>Option 4:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode py"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> ((sat[<span class="st">&#39;Math&#39;</span>] <span class="op">/</span> sat[<span class="st">&#39;Verbal&#39;</span>]) <span class="op">&gt;</span> <span class="dv">1</span>).mean() <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Option 1</p></li>
<li><p><input type="radio" disabled="" /> Option 2</p></li>
<li><p><input type="radio" disabled="" /> Option 3</p></li>
<li><p><input type="radio" disabled="" /> Option 4</p></li>
</ul>
<p><br></p>
<h3 id="problem-8.2">Problem 8.2</h3>
<p>Suppose we train a classifier, named Classifier 1, and it achieves an
accuracy of <span class="math inline">\frac{5}{9}</span> on our training
set.</p>
<p>Typically, root mean squared error (RMSE) is used as a performance
metric for regression models, but mathematically, nothing is stopping us
from using it as a performance metric for classification models as
well.</p>
<p>What is the RMSE of Classifier 1 on our training set? Give your
answer as a <strong>simplified fraction</strong>.</p>
<p><br></p>
<h3 id="problem-8.3">Problem 8.3</h3>
<p>While Classifier 1’s accuracy on our training set is <span
class="math inline">\frac{5}{9}</span>, its accuracy on our test set is
<span class="math inline">\frac{1}{4}</span>. Which of the following
scenarios is most likely?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> Classifier 1 overfit to our training set; we need to increase its
complexity.</p></li>
<li><p><input type="radio" disabled="" /> Classifier 1 overfit to our training set; we need to decrease its
complexity.</p></li>
<li><p><input type="radio" disabled="" /> Classifier 1 underfit to our training set; we need to increase its
complexity.</p></li>
<li><p><input type="radio" disabled="" /> Classifier 1 underfit to our training set; we need to decrease its
complexity.</p></li>
</ul>
<p><br></p>
<p>For the remainder of this question, suppose we train another
classifier, named Classifier 2, again on our training set. Its
performance on the training set is described in the confusion matrix
below. Note that the columns of the confusion matrix have been
separately normalized so that each has a sum of 1.</p>
<center><img src='../assets/images/old-from-80/wi23-final/conf-matrix.png' width=30%></center>
<p><br></p>
<h3 id="problem-8.4">Problem 8.4</h3>
<p>Suppose <code>conf</code> is the DataFrame above. Which of the
following evaluates to a Series of length 2 whose only unique value is
the number <code>1</code>?</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <code>conf.sum(axis=0)</code></p></li>
<li><p><input type="radio" disabled="" /> <code>conf.sum(axis=1)</code></p></li>
</ul>
<p><br></p>
<h3 id="problem-8.5">Problem 8.5</h3>
<p>Fill in the blank: the ___ of Classifier 2 is guaranteed to be
0.6.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> precision</p></li>
<li><p><input type="radio" disabled="" /> recall</p></li>
</ul>
<p><br></p>
<p>For your convenience, we show the column-normalized confusion matrix
from the previous page below. You will need to use the specific numbers
in this matrix when answering the following subpart.</p>
<center><img src='../assets/images/old-from-80/wi23-final/conf-matrix.png' width=30%></center>
<p><br></p>
<h3 id="problem-8.6">Problem 8.6</h3>
<p>Suppose a fraction <span class="math inline">\alpha</span> of the
labels in the training set are actually 1 and the remaining <span
class="math inline">1 - \alpha</span> are actually 0. The accuracy of
Classifier 2 is 0.65. What is the value of <span
class="math inline">\alpha</span>? </p>
<p>Hint: If you’re unsure on how to proceed, here are some guiding
questions:</p>
<ul>
<li><p>Suppose the number of <span class="math inline">y</span>-values
that are actually 1 is <span class="math inline">A</span> and that the
number of <span class="math inline">y</span>-values that are actually 0
is <span class="math inline">B</span>. In terms of <span
class="math inline">A</span> and <span class="math inline">B</span>,
what is the accuracy of Classifier 2? Remember, you’ll need to refer to
the numbers in the confusion matrix above.</p></li>
<li><p>What is the relationship between <span
class="math inline">A</span>, <span class="math inline">B</span>, and
<span class="math inline">\alpha</span>? How does it simplify your
calculation for the accuracy in the previous step?</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="problem-9">Problem 9</h2>
<p>Let <span class="math inline">\vec{x} = \begin{bmatrix} x_1 \\ x_2
\end{bmatrix}</span>. Consider the function <span
class="math inline">g(\vec{x}) = (x_1 - 3)^2 + (x_1^2 -
x_2)^2</span>.</p>
<p><br></p>
<h3 id="problem-9.1">Problem 9.1</h3>
<p>Find <span class="math inline">\nabla g(\vec{x})</span>, the gradient
of <span class="math inline">g(\vec{x})</span>, and use it to show that
<span class="math inline">\nabla g\left( \begin{bmatrix} -1 \\ 1
\end{bmatrix} \right) = \begin{bmatrix} -8 \\ 0
\end{bmatrix}</span>.</p>
<p><br></p>
<h3 id="problem-9.2">Problem 9.2</h3>
<p>We’d like to find the vector <span
class="math inline">\vec{x}^*</span> that minimizes <span
class="math inline">g(\vec{x})</span> using gradient descent. Perform
one iteration of gradient descent by hand, using the initial guess <span
class="math inline">\vec{x}^{(0)} = \begin{bmatrix} -1 \\ 1
\end{bmatrix}</span> and the learning rate <span
class="math inline">\alpha = \frac{1}{2}</span>. In other words, what is
<span class="math inline">\vec{x}^{(1)}</span>?</p>
<p><br></p>
<h3 id="problem-9.3">Problem 9.3</h3>
<p>Consider the function <span class="math inline">f(t) = (t - 3)^2 +
(t^2 - 1)^2</span>. Select the true statement below.</p>
<ul class="task-list">
<li><p><input type="radio" disabled="" /> <span class="math inline">f(t)</span> is convex and has a global
minimum.</p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">f(t)</span> is not convex, but has a global
minimum.</p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">f(t)</span> is convex, but doesn’t have a
global minimum.</p></li>
<li><p><input type="radio" disabled="" /> <span class="math inline">f(t)</span> is not convex and doesn’t have
a global minimum.</p></li>
</ul>
<p><br></p>
<hr />
<h2 id="section"><span class="math display"> </span></h2>
<h4
id="feedback-find-an-error-still-confused-have-a-suggestion-let-us-know-here.">👋
Feedback: Find an error? Still confused? Have a suggestion? Let us know
<a href="https://forms.gle/xK4DpWXh9rq8AKP37">here</a>.</h4>
<hr />
</body>
</html>
