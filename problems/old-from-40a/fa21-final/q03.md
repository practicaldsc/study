# BEGIN PROB

<i>Source: [Fall 2021 Final Exam](../fa21-final/index.html), Problem 3</i>

Consider the function $$R(h) = (h - 2)^3$$

Suppose we want to try and minimize $R(h)$ using gradient descent. We choose an initial guess of $h_0 = 1$ and a step size of $\alpha = 1$.

Run the gradient descent algorithm twice, i.e. determine $h_1$ and $h_2$. Show your work. Also, state whether or not gradient descent will eventually find the minimizing value of $h$, given the specified $h_0$ and $\alpha$.

# BEGIN SOLN

 $h_1 = -2$, $h_2 = -50$
 
 No, gradient descent will not converge; $h_i$ will keep getting larger and more negative (i.e. it tends to negative infinity).

$$\frac{dR}{dh} R(h) = 3 (h - 2)^2$$

$$\begin{align*}
    h_1 &= h_0 - \alpha \cdot \frac{dR}{dh} R(h_0) \\
    &= 1 - 3(1 - 2)^2 \\
    &= -2
\end{align*}$$

$$\begin{align*}
    h_2 &= h_1 - \alpha \cdot \frac{dR}{dh} R(h_1) \\
    &= -2 - 3(-2 - 2)^2 \\
    &= -2 - 48 \\
    &= -50
\end{align*}$$

# END SOLN

# END PROB