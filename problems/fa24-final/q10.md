# BEGIN PROB

Suppose we want to create polynomial features and use ridge regression
(i.e. minimize mean squared error with $L_2$ regularization) to fit a
linear model that predicts the number of ingredients in a product given
its price.

To choose the polynomial degree and regularization hyperparameter, we
use cross-validation through `GridSearchCV` in `sklearn` using the code
below.

    searcher = GridSearchCV(
        make_pipeline(PolynomialFeatures(include_bias=False), 
                      Ridge()),
        
        param_grid={"polynomialfeatures__degree": np.arange(1, D + 1), 
                    "ridge__alpha": 2 ** np.arange(1, L + 1)},

        cv=K # K-fold cross-validation.
    ) 
    searcher.fit(X_train, y_train)

Assume that there are $N$ rows in `X_train`, where $N$ is a multiple of
$K$ (the number of folds used for cross-validation).

In each of the parts below, give your answer as an **expression
involving $D$, $L$, $K$, and/or $N$**. Part (a) is done for you as an
example.

# BEGIN SUBPROB

How many combinations of hyperparameters are being considered?

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

(2.5 pts) **Each time** a model is trained, how many points are being
used to train the model?

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

(2.5 pts) **In total**, how many times are `X_train.iloc[1]` and
`X_train.iloc[-1]` **both** used for training a model **at the same
time**? Assume that these two points are in different folds.

# BEGIN SOLUTION

# END SOLUTION

# END SUBPROB

# END PROB