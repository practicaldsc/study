# BEGIN PROB

Let $\vec{x} = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}$. Consider the
function $\displaystyle Q(\vec x) = x_1^2 - 2x_1x_2 + 3x_2^2 - 1$.

# BEGIN SUBPROB

Fill in the blank to complete the definition of $\nabla Q(\vec x)$, the
gradient of $Q$.

$$\nabla Q(\vec x) = \begin{bmatrix} 2(x_1 - x_2) \\ \\ \_\_\_\_ \end{bmatrix}$$

What goes in the blank? Show your work, and put a your final answer,
which should be an **expression involving $x_1$ and/or $x_2$**.

# BEGIN SOLUTION
**Answer**: $\nabla Q(\vec{x}) = \begin{bmatrix} 2(x_1 - x_2) \\ -2x_1 + 6x_2 \end{bmatrix}$

The gradient of $Q(\vec{x})$ is given by:
$$
\nabla Q(\vec{x}) = \begin{bmatrix} \frac{\partial Q}{\partial x_1} \\ \frac{\partial Q}{\partial x_2} \end{bmatrix}
$$

First, compute the partial derivatives:

1. Partial derivative with respect to $x_1$:
$$
Q(x_1, x_2) = x_1^2 - 2x_1x_2 + 3x_2^2 - 1
$$
$$
\frac{\partial Q}{\partial x_1} = 2x_1 - 2x_2
$$

2. Partial derivative with respect to $x_2$:
$$
\frac{\partial Q}{\partial x_2} = -2x_1 + 6x_2
$$

Thus, the gradient is:
$$
\nabla Q(\vec{x}) = \begin{bmatrix} 2(x_1 - x_2) \\ -2x_1 + 6x_2 \end{bmatrix}
$$

<average>87</average>

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

We decide to use gradient descent to minimize $Q$, using an initial
guess of $\vec x^{(0)} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$ and a
learning rate/step size of $\alpha$.

If after one iteration of gradient descent, we have
$\vec{x}^{(1)} = \begin{bmatrix} 1 \\ -4 \end{bmatrix}$, what is
$\alpha$?

( ) $\displaystyle \frac{1}{4}$
( ) $\displaystyle \frac{1}{2}$
( ) $\displaystyle \frac{3}{4}$
( ) $\displaystyle \frac{5}{4}$
( ) $\displaystyle \frac{3}{2}$
( ) $\displaystyle \frac{5}{2}$

# BEGIN SOLUTION
**Final Answer**: $\frac{5}{4}$

In gradient descent, the update rule is:
$$
\vec{x}^{(k+1)} = \vec{x}^{(k)} - \alpha \nabla Q(\vec{x}^{(k)})
$$

We are given:
$$
\vec{x}^{(0)} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}, \quad \vec{x}^{(1)} = \begin{bmatrix} 1 \\ -4 \end{bmatrix}
$$

1. Compute $\nabla Q(\vec{x}^{(0)})$:

Substitute $\vec{x}^{(0)} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$ into the gradient:
$$
\nabla Q(\vec{x}^{(0)}) = \begin{bmatrix} 2(1 - 1) \\ -2(1) + 6(1) \end{bmatrix} = \begin{bmatrix} 0 \\ 4 \end{bmatrix}
$$

2. Use the update rule to find $\alpha$:

From the update rule:
$$
\vec{x}^{(1)} = \vec{x}^{(0)} - \alpha \nabla Q(\vec{x}^{(0)})
$$

Substitute the values:
$$
\begin{bmatrix} 1 \\ -4 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \alpha \begin{bmatrix} 0 \\ 4 \end{bmatrix}
$$

Separate components:
$$
1 = 1 - \alpha(0) \quad \text{(satisfied for any $\alpha$)},
$$
$$
-4 = 1 - \alpha(4)
$$

Solve for $\alpha$:
$$
-4 = 1 - 4\alpha \implies 4\alpha = 5 \implies \alpha = \frac{5}{4}
$$

<average>86</average>

# END SOLUTION

# END SUBPROB

# END PROB