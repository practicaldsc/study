# BEGIN PROB

Consider a dataset of $n$ values, $y_1, y_2, ..., y_n$, all of which are
**positive**. We want to fit a constant model, $H(x) = h$, to the data.

Let $h_p^*$ be the optimal constant prediction that minimizes average
degree-$p$ loss, $R_p(h)$, defined below.

$$R_p(h) = \frac{1}{n} \sum_{i = 1}^n | y_i - h |^p$$

For example, $h_2^*$ is the optimal constant prediction that minimizes
$\displaystyle R_2(h) = \frac{1}{n} \sum_{i = 1}^n |y_i - h|^2$.

In each of the parts below, determine the value of the quantity
provided. By "the data\", we are referring to $y_1, y_2, ..., y_n$.

# BEGIN SUBPROB

$h_0^*$

( ) The standard deviation of the data  
( ) The variance of the data  
( ) The mean of the data  
( ) The median of the data  
( ) The midrange of the data, $\frac{y_\text{min} + y_\text{max}}{2}$  
( ) The mode of the data  
( ) None of the above  

# BEGIN SOLUTION
**Answer**: The mode of the data

The minimizer of empirical risk for the constant model when using zero-one loss is the mode. 
# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

$h_1^*$

( ) The standard deviation of the data  
( ) The variance of the data  
( ) The mean of the data  
( ) The median of the data  
( ) The midrange of the data, $\frac{y_\text{min} + y_\text{max}}{2}$  
( ) The mode of the data  
( ) None of the above  

# BEGIN SOLUTION
**Answer**: The median of the data 

The minimizer of empirical risk for the constant model when using absolute loss is the median.

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

$R_1(h_1^*)$

( ) The standard deviation of the data  
( ) The variance of the data  
( ) The mean of the data  
( ) The median of the data  
( ) The midrange of the data, $\frac{y_\text{min} + y_\text{max}}{2}$  
( ) The mode of the data  
( ) None of the above  

# BEGIN SOLUTION
**Answer**: None of the above

The minimizer of empirical risk for $R_1(h_1^*)$ is the sum of absolute deviations from the median divided by $n$.

$R_1(h_1^*)$ represents the sum of absolute deviations from the median divided by $n$:

$$R_1(h_1^*) = \frac{1}{n} \sum_{i=1}^n |y_i - h_1^*|$$
# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

$h_2^*$

( ) The standard deviation of the data  
( ) The variance of the data  
( ) The mean of the data  
( ) The median of the data  
( ) The midrange of the data, $\frac{y_\text{min} + y_\text{max}}{2}$  
( ) The mode of the data  
( ) None of the above  

# BEGIN SOLUTION
**Answer**: The mean of the data

The minimizer of empirical risk for the constant model when using squared loss is the mean.

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

$R_2(h_2^*)$

( ) The standard deviation of the data  
( ) The variance of the data  
( ) The mean of the data  
( ) The median of the data  
( ) The midrange of the data, $\frac{y_\text{min} + y_\text{max}}{2}$  
( ) The mode of the data  
( ) None of the above  

# BEGIN SOLUTION
**Answer**: The variance of the data

The minimizer of empirical risk for $R_2(h_2^*)$ is the mean squared error, which is equivalent to the variance of the data when $h_2^*$ equals the mean.

$R_2(h_2^*)$ represents the mean squared error:

$$ R_2(h_2^*) = \frac{1}{n} \sum_{i=1}^n (y_i - h_2^*)^2 $$

# END SOLUTION

# END SUBPROB

Now, suppose we want to find the optimal constant prediction,
$h_\text{U}^*$, using the "Ulta\" loss function, defined below.

$$L_U(y_i, h) = y_i (y_i - h)^2$$

# BEGIN SUBPROB

To find $h_\text{U}^*$, suppose we minimize average Ulta loss
(with no regularization). How does $h_\text{U}^*$ compare to the mean of
the data, $M$?

( ) $h_\text{U}^* > M$
( ) $h_\text{U}^* \geq M$
( ) $h_\text{U}^* = M$
( ) $h_\text{U}^* \leq M$
( ) $h_\text{U}^* < M$

# BEGIN SOLUTION
**Answer**: $h_\text{U}^* \geq M$

Since we're multiplying by $y_i$, the Ulta loss function skews the optimal prediction higher to reduce the impact of larger $y_i$ values on the loss. 

# END SOLUTION

# END SUBPROB

Now, to find the optimal constant prediction, we will instead minimize
**regularized** average Ulta loss, $R_\lambda(h)$, where $\lambda$ is a
non-negative regularization hyperparameter:

$$R_\lambda(h) = \left( \frac{1}{n} \sum_{i = 1}^n y_i (y_i - h)^2 \right) + \lambda h^2$$

It can be shown that
$\displaystyle \frac{\partial R_\lambda(h)}{\partial h}$, the derivative
of $R_\lambda(h)$ with respect to $h$, is:

$$\frac{\partial R_\lambda(h)}{\partial h} = -2 \left( \frac{1}{n} \sum_{i = 1}^n y_i (y_i - h) - \lambda h \right)$$

# BEGIN SUBPROB

Find $h^*$, the constant prediction that minimizes $R_\lambda(h)$. Show
your work, and put a around your final answer, which should be an
**expression in terms of $y_i$, $n$, and/or $\lambda$**.

# BEGIN SOLUTION
**Answer**: $h^* = \frac{\sum_{i = 1}^n y_i^2}{\sum_{i = 1}^n y_i + n\lambda}$


To minimize the regularized average Ulta loss, we solve the equation by setting the derivative to zero and solving for $h$.

Set the derivative to zero:

$$ \frac{\partial R_\lambda(h)}{\partial h} = 0 $$

$$ -2 \left( \frac{1}{n} \sum_{i = 1}^n y_i (y_i - h) \right) + 2\lambda h = 0 $$

Simplify:

$$ \frac{1}{n} \sum_{i = 1}^n y_i^2 - \frac{1}{n} \sum_{i = 1}^n y_i h - \lambda h = 0 $$

Combine terms:

$$ \frac{1}{n} \sum_{i = 1}^n y_i^2 = h \left( \frac{1}{n} \sum_{i = 1}^n y_i + \lambda \right) $$

Solve for $h$:

$$ h^* = \frac{\frac{1}{n} \sum_{i = 1}^n y_i^2}{\frac{1}{n} \sum_{i = 1}^n y_i + \lambda} $$

$$ h^* = \frac{\sum_{i = 1}^n y_i^2}{\sum_{i = 1}^n y_i + n\lambda} $$
# END SOLUTION

# END SUBPROB

# END PROB
