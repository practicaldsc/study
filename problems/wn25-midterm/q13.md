# BEGIN PROB

Suppose we'd like to fit a constant model, $H(x_i) = h$, to predict the
number of minutes a delivery will take. To find the optimal constant
prediction, $h^*$, we decide to use the **$\alpha \beta$-balanced** loss
function, defined below:

$$L_{\alpha \beta}(y_i, h) = (\alpha y_i - \beta h)^2$$

where $\alpha$ and $\beta$ are both constants, and $\beta \neq 0$.

Below, assume $\bar{y} = \frac{1}{n} \sum_{i = 1}^n y_i$ is the mean
number of minutes a delivery took.

# BEGIN SUBPROB

Suppose $\alpha = 3$ and $\beta = 3$, so
$L_{\alpha \beta}(y_i, h) = (3y_i - 3h)^2$.

What is the optimal constant prediction, $h^*$, that minimizes average
$\alpha \beta$-balanced loss?

( ) $\bar{y}$ 
( ) $\frac{1}{2} \bar{y}$ 
( ) $2 \bar{y}$ 
( ) $\frac{1}{3} \bar{y}$ 
( ) $3 \bar{y}$ 
( ) $\frac{1}{6} \bar{y}$
( ) $6 \bar{y}$

# BEGIN SOLUTION
**Answer**: $\bar{y}$

To find the optimal parameter, we have to minimize the average loss function. The loss function is given as: $L_{\alpha \beta}(y_i, h) = (3y_i - 3h)^2$

To minimize this, we need to find the value of $h$ that minimizes the sum of squared errors for all $y_{i}$. We do this by taking the derivative of the loss function and solving it by setting it to zero. 
 
Expanding the squared term:
$$ \sum_{i=1}^{n} (9y_i^2 - 18y_i h + 9h^2)$$

Using summation properties:
$$
9 \sum_{i=1}^{n} y_i^2 - 18h \sum_{i=1}^{n} y_i + 9h^2 n
$$

Differentiating:
$$
\frac{d}{dh} \left( 9 \sum_{i=1}^{n} y_i^2 - 18h \sum_{i=1}^{n} y_i + 9h^2 n \right)
$$

Since the first term $9 \sum_{i=1}^{n} y_i^2$ does not depend on $h$, its derivative is zero.

Differentiating the remaining terms:
$$
\frac{d}{dh} (-18h \sum_{i=1}^{n} y_i) = -18 \sum_{i=1}^{n} y_i
$$

$$
\frac{d}{dh} (9h^2 n) = 18h n
$$

Thus, the derivative of the total loss is:
$$
-18 \sum_{i=1}^{n} y_i + 18h n
$$

Setting the derivative equal to zero:
$$
-18 \sum_{i=1}^{n} y_i + 18h n = 0
$$

Dividing both sides by 18:
$$
- \sum_{i=1}^{n} y_i + h n = 0
$$

Solving for $h$:
$$
h = \frac{\sum_{i=1}^{n} y_i}{n}
$$

This is equivalent to mean of $\bar{y}$. Thus, the optimal constant prediction is the mean of the delivery times.

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Suppose $\alpha = 6$ and $\beta = 3$, so
$L_{\alpha \beta}(y_i, h) = (6y_i - 3h)^2$.

What is the optimal constant prediction, $h^*$, that minimizes average
$\alpha \beta$-balanced loss?

( ) $\bar{y}$ 
( ) $\frac{1}{2} \bar{y}$ 
( ) $2 \bar{y}$ 
( ) $\frac{1}{3} \bar{y}$ 
( ) $3 \bar{y}$ 
( ) $\frac{1}{6} \bar{y}$ 
( ) $6 \bar{y}$

# BEGIN SOLUTION
**Answer**: $2 \bar{y}$ 

To find the optimal parameter, we have to minimize the average loss function. The loss function is given as:  
$$L_{\alpha \beta}(y_i, h) = (6y_i - 3h)^2$$  

To minimize this, we need to find the value of $h$ that minimizes the sum of squared errors for all $y_i$. We do this by taking the derivative of the loss function and solving it by setting it to zero.  

Expanding the squared term:
$$ \sum_{i=1}^{n} (36y_i^2 - 36y_i h + 9h^2) $$

Using summation properties:
$$
36 \sum_{i=1}^{n} y_i^2 - 36h \sum_{i=1}^{n} y_i + 9h^2 n
$$

Differentiating:
$$
\frac{d}{dh} \left( 36 \sum_{i=1}^{n} y_i^2 - 36h \sum_{i=1}^{n} y_i + 9h^2 n \right)
$$

Since the first term $36 \sum_{i=1}^{n} y_i^2$ does not depend on $h$, its derivative is zero.

Differentiating the remaining terms:
$$
\frac{d}{dh} (-36h \sum_{i=1}^{n} y_i) = -36 \sum_{i=1}^{n} y_i
$$

$$
\frac{d}{dh} (9h^2 n) = 18h n
$$

Thus, the derivative of the total loss is:
$$
-36 \sum_{i=1}^{n} y_i + 18h n
$$

Setting the derivative equal to zero:
$$
-36 \sum_{i=1}^{n} y_i + 18h n = 0
$$

Dividing both sides by 18:
$$
-2 \sum_{i=1}^{n} y_i + h n = 0
$$

Solving for $h$:
$$
h = \frac{2 \sum_{i=1}^{n} y_i}{n} = 2 \bar{y}
$$

Thus, the optimal constant prediction is $2 \bar{y}$.

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Find the optimal constant prediction, $h^*$, that minimizes average
$\alpha \beta$-balanced loss **in general**, for any valid choice of
$\alpha$ and $\beta$. Show your work, and $\boxed{\text{box}}$ your
final answer, which should be an expression involving $\bar{y}$,
$\alpha$, $\beta$, and/or other constants.


# BEGIN SOLUTION
**Answer**: $\frac{\alpha}{\beta} \bar{y}$

To find the optimal parameter, we have to minimize the average loss function. The loss function is given as:  
$$L_{\alpha \beta}(y_i, h) = (\alpha y_i - \beta h)^2$$  

To minimize this, we need to find the value of $h$ that minimizes the sum of squared errors for all $y_i$. We do this by taking the derivative of the loss function and solving it by setting it to zero.  

Expanding the squared term:
$$ \sum_{i=1}^{n} (\alpha^2 y_i^2 - 2\alpha\beta y_i h + \beta^2 h^2) $$

Using summation properties:
$$
\alpha^2 \sum_{i=1}^{n} y_i^2 - 2\alpha\beta h \sum_{i=1}^{n} y_i + \beta^2 h^2 n
$$

Differentiating:
$$
\frac{d}{dh} \left( \alpha^2 \sum_{i=1}^{n} y_i^2 - 2\alpha\beta h \sum_{i=1}^{n} y_i + \beta^2 h^2 n \right)
$$

Since the first term $\alpha^2 \sum_{i=1}^{n} y_i^2$ does not depend on $h$, its derivative is zero.

Differentiating the remaining terms:
$$
\frac{d}{dh} (-2\alpha\beta h \sum_{i=1}^{n} y_i) = -2\alpha\beta \sum_{i=1}^{n} y_i
$$

$$
\frac{d}{dh} (\beta^2 h^2 n) = 2\beta^2 h n
$$

Thus, the derivative of the total loss is:
$$
-2\alpha\beta \sum_{i=1}^{n} y_i + 2\beta^2 h n
$$

Setting the derivative equal to zero:
$$
-2\alpha\beta \sum_{i=1}^{n} y_i + 2\beta^2 h n = 0
$$

Dividing both sides by 2:
$$
- \alpha\beta \sum_{i=1}^{n} y_i + \beta^2 h n = 0
$$

Solving for $h$:
$$
h = \frac{\alpha\beta \sum_{i=1}^{n} y_i}{\beta^2 n}
$$

We substitute $\sum_{i=1}^{n} y_i = n\bar{y}$ into the equation:
$$
h = \frac{\alpha\beta (n\bar{y})}{\beta^2 n}
$$

This simplified gives us 
$$
h^* = \frac{\alpha}{\beta} \bar{y}
$$



# END SOLUTION

# END SUBPROB

# END PROB