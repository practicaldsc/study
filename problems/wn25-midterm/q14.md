# BEGIN PROB

Suppose we'd like to predict the number of minutes a delivery will take
($y$) as a function of distance ($x$). To do so, we look to our dataset
of $n$ deliveries, $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$, and fit
two simple linear models:

-   $F(x_i) = a_0 + a_1 x_i$, where:
    $$a_1 = r \frac{\sigma_y}{\sigma_x}, \qquad a_0 = \bar{y} - r \frac{\sigma_y}{\sigma_x} \bar{x}$$

    Here, $r$ is the correlation coefficient between $x$ and $y$,
    $\bar{x}$ and $\bar{y}$ are the means of $x$ and $y$, respectively,
    and $\sigma_x$ and $\sigma_y$ are the standard deviations of $x$ and
    $y$, respectively.

-   $G(x_i) = b_0 + b_1 x_i$, where $b_0$ and $b_1$ are chosen such that
    the line $G(x_i) = b_0 + b_1 x_i$ minimizes **mean absolute error**
    on the dataset. Assume that no other line minimizes mean absolute
    error on the dataset, i.e. that the values of $b_0$ and $b_1$ are
    unique.

# BEGIN SUBPROB

Fill in the $\boxed{\text{???}}$:
$$\displaystyle \sum_{i = 1}^n (y_i - G(x_i))^2 \:\:\: \boxed{???} \:\:\: \sum_{i = 1}^n (y_i - F(x_i))^2$$

( ) $\geq$ 
( ) $>$
( ) $=$ 
( ) $<$ 
( ) $\leq$ 
( ) Impossible to tell

# BEGIN SOLUTION
**Answer**: >

The quantity $\frac{1}{n} \sum_{i = 1}^n (y_i - F(x_i))^2$ 
is the **mean squared error** (MSE) of model $F$. By definition, $F$ is the line that minimizes MSE over all possible linear models.

The quantity  $\frac{1}{n} \sum_{i = 1}^n (y_i - G(x_i))^2$
is the mean squared error of model $G$, which is not optimized for MSE but rather for **mean absolute error** (MAE).

Since $F$ is specifically constructed to minimize the squared error, and $G$ is not, we must have:  
$$ \sum_{i = 1}^{n} (y_i - G(x_i))^2 > \sum_{i = 1}^{n} (y_i - F(x_i))^2 $$


# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Fill in the $\boxed{\text{???}}$:
$$\displaystyle \left( \sum_{i = 1}^n \big| y_i - G(x_i) \big| \right)^2 \:\:\: \boxed{???} \:\:\: \left( \sum_{i = 1}^n \big| y_i - F(x_i) \big| \right)^2$$

( ) $\geq$ 
( ) $>$ 
( ) $=$ 
( ) $<$ 
( ) $\leq$ 
( ) Impossible to tell

# BEGIN SOLUTION
**Answer**: <

The quantity $\frac{1}{n} \sum_{i = 1}^n | y_i - G(x_i) |$  is the **mean absolute error** (MAE) of model $G$. By definition, $G$ is the line that minimizes MAE over all possible linear models.

The quantity $\frac{1}{n} \sum_{i = 1}^n | y_i - F(x_i) |$ is the mean absolute error of model $F$, which is not optimized for MAE but rather for **mean squared error** (MSE).

Since $G$ is specifically constructed to minimize the absolute error, and $F$ is not, we must have:  
$$ \sum_{i = 1}^{n} | y_i - G(x_i) | < \sum_{i = 1}^{n} | y_i - F(x_i) | $$

Squaring both sides preserves the inequality (since both sides are non-negative), so:  
$$ \left( \sum_{i = 1}^{n} | y_i - G(x_i) | \right)^2 < \left( \sum_{i = 1}^{n} | y_i - F(x_i) | \right)^2 $$

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Below, we've drawn both lines, $F$, and $G$, along with a scatter plot
of the original $n$ deliveries.

<center>
<img src="../assets/images/wn25-midterm/regression.png" width=50%>
</center>
Which line corresponds to line **$F$**? 

( ) Line 1 
( ) Line 2

# BEGIN SOLUTION
**Answer**: Line 1

The key idea is that models trained with squared loss (MSE) are more sensitive to outliers than models trained with absolute loss (MAE).  

Since Line 1 appears to be "pulled up" more strongly by an outlier, it suggests that this line was influenced more heavily by extreme values. This behavior aligns with how MSE-based regression works: outliers have a greater impact on the overall loss because squaring the errors makes large deviations even more significant.  

In contrast, MAE-based regression (Line 2) is less sensitive to outliers because absolute differences do not grow as quickly.  

Therefore, Line 1 corresponds to $F$, the MSE-minimizing line.  

# END SOLUTION

# END SUBPROB

# END PROB