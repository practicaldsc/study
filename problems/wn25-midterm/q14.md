# BEGIN PROB

Suppose we'd like to predict the number of minutes a delivery will take
($y$) as a function of distance ($x$). To do so, we look to our dataset
of $n$ deliveries, $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$, and fit
two simple linear models:

-   $F(x_i) = a_0 + a_1 x_i$, where:
    $$a_1 = r \frac{\sigma_y}{\sigma_x}, \qquad a_0 = \bar{y} - r \frac{\sigma_y}{\sigma_x} \bar{x}$$

    Here, $r$ is the correlation coefficient between $x$ and $y$,
    $\bar{x}$ and $\bar{y}$ are the means of $x$ and $y$, respectively,
    and $\sigma_x$ and $\sigma_y$ are the standard deviations of $x$ and
    $y$, respectively.

-   $G(x_i) = b_0 + b_1 x_i$, where $b_0$ and $b_1$ are chosen such that
    the line $G(x_i) = b_0 + b_1 x_i$ minimizes **mean absolute error**
    on the dataset. Assume that no other line minimizes mean absolute
    error on the dataset, i.e. that the values of $b_0$ and $b_1$ are
    unique.

# BEGIN SUBPROB

Fill in the $\boxed{\text{???}}$:
$$\displaystyle \sum_{i = 1}^n (y_i - G(x_i))^2 \:\:\: \boxed{???} \:\:\: \sum_{i = 1}^n (y_i - F(x_i))^2$$

( ) $\geq$ 
( ) $>$
( ) $=$ 
( ) $<$ 
( ) $\leq$ 
( ) Impossible to tell

# BEGIN SOLUTION
**Answer** `>`

The function $F(x)$ is the line that minimizes mean squared error (MSE), while $G(x)$ is the line that minimizes mean absolute error (MAE).  

The sum of squared errors (SSE) is the total squared difference between actual and predicted values, which is closely tied to MSE. Since $F$ is specifically chosen to minimize MSE, its SSE must be strictly smaller than that of any other line, including $G$.  

Thus, the sum of squared errors for $G$ is greater than the sum of squared errors for $F$, making the correct answer:  
$$ \sum_{i = 1}^{n} (y_i - G(x_i))^2 > \sum_{i = 1}^{n} (y_i - F(x_i))^2 $$  


# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Fill in the $\boxed{\text{???}}$:
$$\displaystyle \left( \sum_{i = 1}^n \big| y_i - G(x_i) \big| \right)^2 \:\:\: \boxed{???} \:\:\: \left( \sum_{i = 1}^n \big| y_i - F(x_i) \big| \right)^2$$

( ) $\geq$ 
( ) $>$ 
( ) $=$ 
( ) $<$ 
( ) $\leq$ 
( ) Impossible to tell

# BEGIN SOLUTION
**Answer** `<`

The function $G(x)$ is the line that minimizes mean absolute error (MAE), meaning it has the smallest sum of absolute errors (SAE), which is given by:  
$$ \sum_{i=1}^{n} | y_i - G(x_i) | $$  

Since $G$ minimizes MAE, its SAE must be smaller than the SAE of any other line, including $F$.  

Now, note that the expression given in the problem **squares the entire SAE**. Since $G$ has the smallest SAE, its squared SAE will also be smaller than that of $F$:  
$$ \left( \sum_{i = 1}^{n} | y_i - G(x_i) | \right)^2 < \left( \sum_{i = 1}^{n} | y_i - F(x_i) | \right)^2 $$  

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Below, we've drawn both lines, $F$, and $G$, along with a scatter plot
of the original $n$ deliveries.

<center>
<img src="../assets/images/wn25-midterm/regression.png" width=50%>
</center>
Which line corresponds to line **$F$**? 

( ) Line 1 
( ) Line 2

# BEGIN SOLUTION
**Answer** `Line 1`

The key idea is that models trained with squared loss (MSE) are more sensitive to outliers than models trained with absolute loss (MAE).  

Since Line 1 appears to be "pulled up" more strongly by an outlier, it suggests that this line was influenced more heavily by extreme values. This behavior aligns with how MSE-based regression works: outliers have a greater impact on the overall loss because squaring the errors makes large deviations even more significant.  

In contrast, MAE-based regression (Line 2) is less sensitive to outliers because absolute differences do not grow as quickly.  

Therefore, Line 1 corresponds to $F$, the MSE-minimizing line.  

# END SOLUTION

# END SUBPROB

# END PROB